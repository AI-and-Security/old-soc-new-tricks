{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Security Data Analysis Workshop\n",
    "## Blue Team Focus: When to use AI/ML vs Basic Methods\n",
    "\n",
    "This notebook demonstrates when to use simple statistical methods vs machine learning \n",
    "for cybersecurity analysis. Each module compares both approaches with realistic datasets.\n",
    "\n",
    "## Setup and Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab():\n",
    "    %pip install -r \"https://raw.githubusercontent.com/AI-and-Security/old-soc-new-tricks/main/requirements-colab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Using data directory: ../data\n"
     ]
    }
   ],
   "source": [
    "# Set up data directory based on environment\n",
    "if is_colab():\n",
    "    # Create data directory in Colab\n",
    "    import os\n",
    "    DATA_DIR = \"./data\"\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    \n",
    "    # Download data files from GitHub repository\n",
    "    !git clone https://github.com/AI-and-Security/old-soc-new-tricks.git temp_repo\n",
    "    !mkdir -p {DATA_DIR}\n",
    "    !cp -r temp_repo/data/* {DATA_DIR}/\n",
    "    !rm -rf temp_repo\n",
    "    print(\"‚úÖ Data files downloaded to Colab environment\")\n",
    "else:\n",
    "    # Local environment - use relative path\n",
    "    DATA_DIR = \"../data\"\n",
    "\n",
    "print(f\"üìÇ Using data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt, timedelta\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# Lesson 1: The Overwhelmed SOC Analyst\n",
    "# **Persona**: Junior analyst drowning in thousands of alerts/entries in traffic logs. Note: Applicable to both threat hunters and SOC analysts. SOC does it after an alert to determine ‚Äúinvestigation worthy‚Äù or not, threat hunters find the suspicious activity proactively.\n",
    "\n",
    "# \n",
    "# **Scenario**: You have network traffic logs and need to quickly identify suspicious activity.\n",
    "# \n",
    "# **Question**: Should you use Excel pivot tables or machine learning?\n",
    "\n",
    "# 1.1 Import Network Traffic Dataset\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = pd.read_csv(f\"{DATA_DIR}/network_traffic.csv\")\n",
    "traffic_df['timestamp'] = pd.to_datetime(traffic_df['timestamp'])\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(traffic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Basic Analysis (Excel-Style in Python)\n",
    "**Let's generate some basic statistics! You can use a tool like Excel for this**\n",
    "**type of analysis, but you can also do this using python and pandas!**\n",
    "\n",
    "Let's look for:\n",
    "- Top talkers by bytes sent\n",
    "- Unusual ports (simple frequency analysis)\n",
    "- Large transfers (95th percentile threshold)\n",
    "- Quick suspicious IP identification based on a pre-determined list of \"suspicious\" IPs\n",
    "\n",
    "Pros:\n",
    "- Very quick analysis\n",
    "- Summary statistics\n",
    "- Explainable!\n",
    "\n",
    "Cons:\n",
    "- No insight into complex behavior patterns\n",
    "- Must pre-determine statistics you want to examine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_traffic_analysis(df):\n",
    "    \"\"\"Basic analysis that mirrors Excel pivot tables and filters\"\"\"\n",
    "    \n",
    "    print(\"üîé BASIC ANALYSIS (Excel-style approach)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analysis 1: Top talkers by bytes sent\n",
    "    print(\"\\nüìà TOP 10 SOURCES BY TOTAL BYTES:\")\n",
    "    top_sources = df.groupby('source_ip')['bytes'].agg(['sum', 'count', 'mean']).round(2)\n",
    "    top_sources.columns = ['total_bytes', 'connections', 'avg_bytes']\n",
    "    top_sources = top_sources.sort_values('total_bytes', ascending=False)\n",
    "    print(top_sources.head(10))\n",
    "    \n",
    "    # Analysis 2: Unusual ports (simple frequency analysis)\n",
    "    print(\"\\nüîç UNUSUAL PORTS (used ‚â§ 5 times):\")\n",
    "    port_counts = df['destination_port'].value_counts()\n",
    "    unusual_ports = port_counts[port_counts <= 5]\n",
    "    print(f\"Found {len(unusual_ports)} unusual ports:\")\n",
    "    print(unusual_ports.head(10))\n",
    "    \n",
    "    # Analysis 3: Large transfers (95th percentile threshold)\n",
    "    threshold = df['bytes'].quantile(0.95)\n",
    "    large_transfers = df[df['bytes'] > threshold]\n",
    "    print(f\"\\nüìä LARGE TRANSFERS (> {threshold:,.0f} bytes):\")\n",
    "    print(f\"Found {len(large_transfers)} large transfers\")\n",
    "    \n",
    "    large_by_source = large_transfers.groupby('source_ip').agg({\n",
    "        'bytes': ['count', 'sum', 'max'],\n",
    "        'destination_port': lambda x: list(x.unique())\n",
    "    })\n",
    "    large_by_source.columns = ['transfer_count', 'total_bytes', 'max_bytes', 'ports_used']\n",
    "    print(large_by_source.head())\n",
    "    \n",
    "    # Quick suspicious IP identification\n",
    "    suspicious_keywords = ['185.', '194.', '91.', '203.']\n",
    "    external_ips = df[df['source_ip'].str.contains('|'.join(suspicious_keywords), na=False)]\n",
    "    \n",
    "    print(f\"\\nüö® EXTERNAL SOURCE IPs:\")\n",
    "    if len(external_ips) > 0:\n",
    "        ext_summary = external_ips.groupby('source_ip').agg({\n",
    "            'bytes': ['count', 'sum'],\n",
    "            'destination_port': lambda x: list(x.unique())\n",
    "        })\n",
    "        ext_summary.columns = ['connections', 'total_bytes', 'ports_used']\n",
    "        print(ext_summary)\n",
    "    else:\n",
    "        print(\"No external IPs detected with basic pattern matching\")\n",
    "    \n",
    "    return {\n",
    "        'top_sources': top_sources,\n",
    "        'unusual_ports': unusual_ports,\n",
    "        'large_transfers': large_transfers,\n",
    "        'external_ips': external_ips\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the analysis\n",
    "start_time = time.time()\n",
    "basic_results = basic_traffic_analysis(traffic_df)\n",
    "basic_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Basic analysis completed in {basic_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Machine Learning Analysis\n",
    "**We will use an isolation forest to identify anomalies in this dataset.**\n",
    "\n",
    "**What is an isolation forest, and why would we use this type of algorithm?**\n",
    "The isolation forest algorithm is one ML algorithm which answers the question,\n",
    "\"Can you show me data points that are anomalous?\" This algorithm is one example \n",
    "of a machine learning algorithm that is relatively efficient and low memory, \n",
    "which makes it a great algorithm for large datasets. \n",
    "\n",
    "**How This Applies to Security Data:**\n",
    "Imagine you have 10,000 network connections. Most are normal:\n",
    "\n",
    "Employee checking email\n",
    "Someone browsing CNN.com\n",
    "Automatic software updates\n",
    "\n",
    "But one connection is weird:\n",
    "\n",
    "Coming from an IP in North Korea\n",
    "Downloading 50GB of customer data\n",
    "At 3 AM on a Sunday\n",
    "\n",
    "The weird connection is easy to isolate with just a few \"cuts\":\n",
    "\n",
    "- \"Is the IP from a normal location?\" ‚Üí No (isolates 90% of traffic)\n",
    "\n",
    "- \"Is the data volume normal?\" ‚Üí No (isolates 95% of remaining)\n",
    "\n",
    "- \"Is the time normal?\" ‚Üí No (isolated!)\n",
    "\n",
    "The normal connections are hard to isolate - they blend in with thousands of others.\n",
    "The \"Forest\" Part:\n",
    "We don't just build one \"decision tree\" - we build many (a forest!). Each tree asks different random questions:\n",
    "\n",
    "- Tree 1: \"IP location?\" ‚Üí \"Data volume?\" ‚Üí \"Time of day?\"\n",
    "\n",
    "- Tree 2: \"Port number?\" ‚Üí \"Duration?\" ‚Üí \"User type?\"\n",
    "\n",
    "- Tree 3: \"Protocol?\" ‚Üí \"Frequency?\" ‚Üí \"Destination?\"\n",
    "\n",
    "If something is truly anomalous, it should be easy to isolate in MOST trees. If something only looks weird in one tree, it's probably just normal variation. This algorithm might be a good one for some use cases because...\n",
    "\n",
    "‚úÖ No Training Required: You don't need examples of \"good\" vs \"bad\" - it just finds things that don't fit the pattern.\n",
    "\n",
    "‚úÖ Finds Unknown Threats: Traditional security tools look for known bad stuff. Isolation Forest finds anything that's weird, including brand-new attacks.\n",
    "\n",
    "‚úÖ Fast & Scalable: Each tree is simple, so you can analyze millions of records quickly.\n",
    "\n",
    "Pros:\n",
    "- Allows you to discover and examine complex behavior patterns\n",
    "- Incorporates context into your analysis\n",
    "- Depending on the features extracted, can be explainable.\n",
    "\n",
    "Cons:\n",
    "- The performance of the Isolation Forest algorithm is highly dependent on the selection of its parameters.  \n",
    "- More complex algorithm-- caution should be used if you don't know how it works!\n",
    "- Depending on the features, can be hard to explain!\n",
    "- May produce false positives/false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_traffic_analysis(df):\n",
    "    \"\"\"ML-based anomaly detection for network traffic\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ MACHINE LEARNING ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Feature engineering: Create behavioral profiles per source IP\n",
    "    print(\"\\nüîß Creating behavioral features...\")\n",
    "    \n",
    "    features = df.groupby('source_ip').agg({\n",
    "        'bytes': ['sum', 'mean', 'std', 'max', 'count'],\n",
    "        'destination_ip': 'nunique',\n",
    "        'destination_port': ['nunique', lambda x: list(x)],\n",
    "        'timestamp': lambda x: (x.max() - x.min()).total_seconds() / 3600  # session duration in hours\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    features.columns = ['bytes_sum', 'bytes_mean', 'bytes_std', 'bytes_max', 'connection_count', \n",
    "                       'unique_destinations', 'unique_ports', 'ports_list', 'session_duration_hours']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    features['bytes_std'] = features['bytes_std'].fillna(0)\n",
    "    \n",
    "    # Add derived features\n",
    "    features['avg_bytes_per_connection'] = features['bytes_sum'] / features['connection_count']\n",
    "    features['port_diversity'] = features['unique_ports'] / features['connection_count']\n",
    "    \n",
    "    # Check for suspicious ports based on pre-determined list of ports\n",
    "    suspicious_ports = [1337, 4444, 8080, 9999, 31337, 6666]\n",
    "    features['has_suspicious_ports'] = features['ports_list'].apply(\n",
    "        lambda ports: any(port in suspicious_ports for port in ports)\n",
    "    ).astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Created features for {len(features)} unique source IPs\")\n",
    "    print(\"\\nüìä Feature summary:\")\n",
    "    display(features[['bytes_sum', 'connection_count', 'unique_destinations', 'unique_ports', 'has_suspicious_ports']].describe())\n",
    "    \n",
    "    # Prepare features for ML (exclude non-numeric columns)\n",
    "    ml_features = features.drop(['ports_list'], axis=1)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(ml_features)\n",
    "    \n",
    "    # Apply Isolation Forest for anomaly detection\n",
    "    print(\"\\nüîç Applying Isolation Forest anomaly detection...\")\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42, n_estimators=100)\n",
    "    anomaly_labels = iso_forest.fit_predict(features_scaled)\n",
    "    \n",
    "    # Get anomaly scores\n",
    "    anomaly_scores = iso_forest.decision_function(features_scaled)\n",
    "    \n",
    "    # Add results back to features\n",
    "    features['anomaly_label'] = anomaly_labels\n",
    "    features['anomaly_score'] = anomaly_scores\n",
    "    \n",
    "    # Analyze anomalies\n",
    "    anomalies = features[features['anomaly_label'] == -1].sort_values('anomaly_score')\n",
    "    \n",
    "    print(f\"\\nüö® ANOMALOUS SOURCE IPs DETECTED: {len(anomalies)}\")\n",
    "    print(\"\\nTop 5 most anomalous IPs:\")\n",
    "    \n",
    "    for i, (ip, row) in enumerate(anomalies.head().iterrows()):\n",
    "        print(f\"\\n{i+1}. {ip} (anomaly score: {row['anomaly_score']:.3f})\")\n",
    "        print(f\"   üìä Total bytes: {row['bytes_sum']:,}\")\n",
    "        print(f\"   üîó Connections: {row['connection_count']}\")\n",
    "        print(f\"   üéØ Unique destinations: {row['unique_destinations']}\")\n",
    "        print(f\"   üîå Unique ports: {row['unique_ports']}\")\n",
    "        print(f\"   ‚ö†Ô∏è  Has suspicious ports: {'Yes' if row['has_suspicious_ports'] else 'No'}\")\n",
    "        print(f\"   üïê Session duration: {row['session_duration_hours']:.1f} hours\")\n",
    "        \n",
    "        # Show actual ports used\n",
    "        actual_data = df[df['source_ip'] == ip]\n",
    "        ports_used = actual_data['destination_port'].value_counts().head(5)\n",
    "        cast_ports = {key: int(value) for key, value in dict(ports_used).items()}\n",
    "        print(f\"   üîå Top ports: {cast_ports}\")\n",
    "    \n",
    "    return {\n",
    "        'features': features,\n",
    "        'anomalies': anomalies,\n",
    "        'model': iso_forest,\n",
    "        'scaler': scaler\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the ML analysis\n",
    "start_time = time.time()\n",
    "ml_results = ml_traffic_analysis(traffic_df)\n",
    "ml_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è ML analysis completed in {ml_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods_module1():\n",
    "    \"\"\"Compare the effectiveness of basic vs ML methods\"\"\"\n",
    "    \n",
    "    print(\"üìä METHOD COMPARISON - MODULE 1\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get the actual suspicious IPs from our data generation\n",
    "    actual_suspicious = ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
    "    \n",
    "    # Basic method results\n",
    "    basic_suspicious = basic_results['external_ips']['source_ip'].unique() if len(basic_results['external_ips']) > 0 else []\n",
    "    \n",
    "    # ML method results\n",
    "    ml_suspicious = ml_results['anomalies'].index.tolist()\n",
    "    \n",
    "    print(f\"üéØ ACTUAL SUSPICIOUS IPs: {actual_suspicious}\")\n",
    "    print(f\"üîç BASIC METHOD found: {list(basic_suspicious)}\")\n",
    "    print(f\"ü§ñ ML METHOD found: {ml_suspicious[:5]}...\")  # Show top 5\n",
    "    \n",
    "    # Calculate detection rates\n",
    "    basic_detected = len(set(basic_suspicious) & set(actual_suspicious))\n",
    "    ml_detected = len(set(ml_suspicious) & set(actual_suspicious))\n",
    "    \n",
    "    print(f\"\\nüìà DETECTION RESULTS:\")\n",
    "    print(f\"   Basic method detected: {basic_detected}/{len(actual_suspicious)} suspicious IPs\")\n",
    "    print(f\"   ML method detected: {ml_detected}/{len(actual_suspicious)} suspicious IPs\")\n",
    "    \n",
    "    # Show timing comparison\n",
    "    print(f\"\\n‚è±Ô∏è TIMING COMPARISON:\")\n",
    "    print(f\"   Basic method: {basic_time:.2f} seconds\")\n",
    "    print(f\"   ML method: {ml_time:.2f} seconds\")\n",
    "    print(f\"   Speed difference: {ml_time/basic_time:.1f}x slower. \\n\\nFor basic analysis on relatively small datasets, \\nthe two methods have similar runtimes, but for larger datasets, ML methods may take longer. \\nIt can also take a while to fine-tune the features extracted and to work through any false positives!\")\n",
    "    \n",
    "    # When to use each method\n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "    print(\"‚úÖ Use BASIC METHOD when:\")\n",
    "    print(\"   ‚Ä¢ You need results very quickly\")\n",
    "    print(\"   ‚Ä¢ Looking for known bad indicators\")\n",
    "    print(\"   ‚Ä¢ Need explainable results for management\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Use ML METHOD when:\")\n",
    "    print(\"   ‚Ä¢ Unknown threat patterns\")\n",
    "    print(\"   ‚Ä¢ Building automated detection\")\n",
    "    print(\"   ‚Ä¢ Complex behavioral analysis needed\")\n",
    "\n",
    "compare_methods_module1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# Lesson 2: The Incident Responder Under Pressure\n",
    "# **Persona**: IR team member with 30 minutes to determine if an alert is real\n",
    "# \n",
    "# **Scenario**: Authentication logs showing potential brute force attacks\n",
    "# \n",
    "# **Question**: Pivot tables or behavioral modeling?\n",
    "\n",
    "# 2.1 Import Authentication Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_df = pd.read_csv(f\"{DATA_DIR}/auth_logs.csv\")\n",
    "auth_df['timestamp'] = pd.to_datetime(auth_df['timestamp'])\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(auth_df.head())\n",
    "\n",
    "# Quick overview\n",
    "print(f\"\\nüìà Event breakdown:\")\n",
    "print(auth_df['event_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2.2 Basic Analysis (Excel-Style)\n",
    "# **‚è±Ô∏è Time Limit: 5 minutes**\n",
    "\n",
    "# %%\n",
    "def basic_auth_analysis(df):\n",
    "    \"\"\"Basic authentication analysis using simple aggregations\"\"\"\n",
    "    \n",
    "    print(\"üîé BASIC AUTH ANALYSIS (Excel-style)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analysis 1: Failed login attempts by source IP\n",
    "    failed_logins = df[df['event_type'] == 'login_failure']\n",
    "    \n",
    "    print(f\"\\nüìä FAILED LOGIN SUMMARY:\")\n",
    "    print(f\"Total failed logins: {len(failed_logins):,}\")\n",
    "    print(f\"Unique source IPs: {failed_logins['source_ip'].nunique()}\")\n",
    "    print(f\"Unique usernames targeted: {failed_logins['username'].nunique()}\")\n",
    "    \n",
    "    # Top IPs by failed attempts\n",
    "    ip_failures = failed_logins.groupby('source_ip').agg({\n",
    "        'username': ['count', 'nunique'],\n",
    "        'timestamp': ['min', 'max']\n",
    "    })\n",
    "    ip_failures.columns = ['total_failures', 'unique_users_targeted', 'first_attempt', 'last_attempt']\n",
    "    ip_failures['attack_duration_minutes'] = (\n",
    "        ip_failures['last_attempt'] - ip_failures['first_attempt']\n",
    "    ).dt.total_seconds() / 60\n",
    "    \n",
    "    ip_failures = ip_failures.sort_values('total_failures', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP 10 SOURCE IPs BY FAILED ATTEMPTS:\")\n",
    "    display(ip_failures.head(10))\n",
    "    \n",
    "    # Simple brute force detection (threshold-based)\n",
    "    brute_force_threshold = 20\n",
    "    potential_attackers = ip_failures[ip_failures['total_failures'] >= brute_force_threshold]\n",
    "    \n",
    "    print(f\"\\nüö® POTENTIAL BRUTE FORCE ATTACKERS (‚â•{brute_force_threshold} failures):\")\n",
    "    if len(potential_attackers) > 0:\n",
    "        for ip, row in potential_attackers.iterrows():\n",
    "            print(f\"\\nüìç {ip}:\")\n",
    "            print(f\"   üí• Total failures: {row['total_failures']}\")\n",
    "            print(f\"   üë§ Users targeted: {row['unique_users_targeted']}\")\n",
    "            print(f\"   ‚è±Ô∏è  Attack duration: {row['attack_duration_minutes']:.1f} minutes\")\n",
    "            \n",
    "            # Show most targeted usernames for this IP\n",
    "            ip_targets = failed_logins[failed_logins['source_ip'] == ip]['username'].value_counts().head(5)\n",
    "            print(f\"   üéØ Top targets: {dict(ip_targets)}\")\n",
    "    else:\n",
    "        print(\"No IPs exceed the brute force threshold\")\n",
    "    \n",
    "    # Time-based analysis\n",
    "    failed_logins['hour'] = failed_logins['timestamp'].dt.hour\n",
    "    hourly_failures = failed_logins.groupby('hour').size()\n",
    "    \n",
    "    print(f\"\\nüïê FAILED LOGINS BY HOUR:\")\n",
    "    peak_hour = hourly_failures.idxmax()\n",
    "    print(f\"Peak hour: {peak_hour}:00 with {hourly_failures[peak_hour]} failures\")\n",
    "    \n",
    "    return {\n",
    "        'ip_failures': ip_failures,\n",
    "        'potential_attackers': potential_attackers,\n",
    "        'hourly_failures': hourly_failures,\n",
    "        'failed_logins': failed_logins\n",
    "    }\n",
    "\n",
    "# Time the basic analysis\n",
    "start_time = time.time()\n",
    "basic_auth_results = basic_auth_analysis(auth_df)\n",
    "basic_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Basic analysis completed in {basic_auth_time:.2f} seconds\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.3 Machine Learning Analysis\n",
    "\n",
    "# %%\n",
    "def ml_auth_analysis(df):\n",
    "    \"\"\"ML-based authentication analysis using behavioral modeling\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ ML AUTHENTICATION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create time windows for behavioral analysis\n",
    "    print(\"\\nüîß Creating behavioral features with time windows...\")\n",
    "    \n",
    "    # Use 10-minute time windows\n",
    "    df['time_window'] = df['timestamp'].dt.floor('10min')\n",
    "    \n",
    "    # Create features per IP per time window\n",
    "    window_features = df.groupby(['source_ip', 'time_window']).agg({\n",
    "        'username': ['nunique', 'count'],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()],\n",
    "        'service': 'nunique'\n",
    "    })\n",
    "    \n",
    "    window_features.columns = ['unique_users', 'total_attempts', 'failures', 'successes', 'unique_services']\n",
    "    \n",
    "    # Calculate rates and ratios\n",
    "    window_features['failure_rate'] = window_features['failures'] / window_features['total_attempts']\n",
    "    window_features['attempts_per_minute'] = window_features['total_attempts'] / 10  # 10-minute windows\n",
    "    window_features['user_diversity'] = window_features['unique_users'] / window_features['total_attempts']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    window_features = window_features.fillna(0)\n",
    "    \n",
    "    # Add IP-level behavioral features\n",
    "    ip_features = df.groupby('source_ip').agg({\n",
    "        'username': 'nunique',\n",
    "        'timestamp': ['count', lambda x: (x.max() - x.min()).total_seconds() / 3600],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()]\n",
    "    })\n",
    "    \n",
    "    ip_features.columns = ['total_unique_users', 'total_attempts', 'session_duration_hours', \n",
    "                          'total_failures', 'total_successes']\n",
    "    ip_features['overall_failure_rate'] = ip_features['total_failures'] / ip_features['total_attempts']\n",
    "    \n",
    "    # Check if IP is external (simple heuristic)\n",
    "    ip_features['is_external'] = ~ip_features.index.str.startswith('192.168.')\n",
    "    ip_features['is_external'] = ip_features['is_external'].astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Created features for {len(window_features)} time windows across {len(ip_features)} IPs\")\n",
    "    \n",
    "    # Apply clustering to find unusual patterns in time windows\n",
    "    print(\"\\nüîç Applying DBSCAN clustering on time window features...\")\n",
    "    \n",
    "    # Select features for clustering\n",
    "    cluster_features = window_features[['unique_users', 'total_attempts', 'failure_rate', \n",
    "                                      'attempts_per_minute', 'user_diversity']].copy()\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(cluster_features)\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=4)\n",
    "    clusters = dbscan.fit_predict(features_scaled)\n",
    "    \n",
    "    # Add cluster labels\n",
    "    window_features['cluster'] = clusters\n",
    "    \n",
    "    # Analyze outliers (cluster -1)\n",
    "    outliers = window_features[window_features['cluster'] == -1]\n",
    "    \n",
    "    print(f\"\\nüö® ANOMALOUS TIME WINDOWS DETECTED: {len(outliers)}\")\n",
    "    \n",
    "    # Group outliers by IP for analysis\n",
    "    outlier_ips = outliers.groupby(level='source_ip').agg({\n",
    "        'total_attempts': ['sum', 'max'],\n",
    "        'failures': ['sum', 'max'],\n",
    "        'failure_rate': 'mean',\n",
    "        'attempts_per_minute': 'max',\n",
    "        'unique_users': 'max'\n",
    "    })\n",
    "    \n",
    "    outlier_ips.columns = ['total_attempts', 'max_attempts_per_window', 'total_failures', \n",
    "                          'max_failures_per_window', 'avg_failure_rate', \n",
    "                          'max_attempts_per_minute', 'max_users_per_window']\n",
    "    \n",
    "    # Sort by severity\n",
    "    outlier_ips['severity_score'] = (\n",
    "        outlier_ips['max_attempts_per_minute'] * 0.4 +\n",
    "        outlier_ips['avg_failure_rate'] * 0.3 +\n",
    "        outlier_ips['max_users_per_window'] * 0.3\n",
    "    )\n",
    "    \n",
    "    outlier_ips = outlier_ips.sort_values('severity_score', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP SUSPICIOUS IPs BY ML ANALYSIS:\")\n",
    "    \n",
    "    for i, (ip, row) in enumerate(outlier_ips.head().iterrows()):\n",
    "        print(f\"\\n{i+1}. {ip} (severity score: {row['severity_score']:.2f})\")\n",
    "        print(f\"   üí• Total attempts: {row['total_attempts']}\")\n",
    "        print(f\"   üìà Max attempts/minute: {row['max_attempts_per_minute']:.1f}\")\n",
    "        print(f\"   ‚ùå Average failure rate: {row['avg_failure_rate']:.2%}\")\n",
    "        print(f\"   üë• Max users targeted in one window: {row['max_users_per_window']}\")\n",
    "        \n",
    "        # Show timeline for this IP\n",
    "        ip_data = df[df['source_ip'] == ip]\n",
    "        print(f\"   üìÖ Active period: {ip_data['timestamp'].min()} to {ip_data['timestamp'].max()}\")\n",
    "        \n",
    "        # Show most common usernames\n",
    "        top_users = ip_data['username'].value_counts().head(3)\n",
    "        print(f\"   üéØ Top targets: {dict(top_users)}\")\n",
    "    \n",
    "    return {\n",
    "        'window_features': window_features,\n",
    "        'ip_features': ip_features,\n",
    "        'outliers': outliers,\n",
    "        'outlier_ips': outlier_ips,\n",
    "        'clusters': clusters\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the ML analysis\n",
    "start_time = time.time()\n",
    "ml_auth_results = ml_auth_analysis(auth_df)\n",
    "ml_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è ML analysis completed in {ml_auth_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods_module2():\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üî¨ **Deep Dive: Method Comparison Analysis**\n",
    "# \n",
    "# Let's create a detailed comparison of how well each method actually performed on our authentication data.\n",
    "\n",
    "# %%\n",
    "    def detailed_method_comparison():\n",
    "        \"\"\"Comprehensive comparison of Excel-style vs ML methods\"\"\"\n",
    "        \n",
    "        print(\"üî¨ DETAILED METHOD COMPARISON ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Get the actual suspicious IPs from our data generation\n",
    "        actual_attackers = ['203.0.113.15', '198.51.100.42', '192.0.2.123', '185.199.108.153']\n",
    "        \n",
    "        # Basic method results\n",
    "        basic_suspicious = basic_auth_results['potential_attackers'].index.tolist()\n",
    "        \n",
    "        # ML method results\n",
    "        ml_suspicious = ml_auth_results['outlier_ips'].index.tolist()\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_data = []\n",
    "        \n",
    "        # Analyze each actual attacker\n",
    "        for ip in actual_attackers:\n",
    "            basic_detected = ip in basic_suspicious\n",
    "            ml_detected = ip in ml_suspicious\n",
    "            \n",
    "            # Get actual behavior data\n",
    "            ip_data = auth_df[auth_df['source_ip'] == ip]\n",
    "            total_attempts = len(ip_data)\n",
    "            failures = len(ip_data[ip_data['event_type'] == 'login_failure'])\n",
    "            unique_users = ip_data['username'].nunique()\n",
    "            time_span = (ip_data['timestamp'].max() - ip_data['timestamp'].min()).total_seconds() / 60\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'ip': ip,\n",
    "                'actual_attacker': True,\n",
    "                'basic_detected': basic_detected,\n",
    "                'ml_detected': ml_detected,\n",
    "                'total_attempts': total_attempts,\n",
    "                'failures': failures,\n",
    "                'failure_rate': failures / total_attempts if total_attempts > 0 else 0,\n",
    "                'unique_users': unique_users,\n",
    "                'time_span_minutes': time_span\n",
    "            })\n",
    "        \n",
    "        # Analyze false positives\n",
    "        all_detected = set(basic_suspicious + ml_suspicious)\n",
    "        false_positives = all_detected - set(actual_attackers)\n",
    "        \n",
    "        for ip in false_positives:\n",
    "            basic_detected = ip in basic_suspicious\n",
    "            ml_detected = ip in ml_suspicious\n",
    "            \n",
    "            # Get behavior data\n",
    "            ip_data = auth_df[auth_df['source_ip'] == ip]\n",
    "            total_attempts = len(ip_data)\n",
    "            failures = len(ip_data[ip_data['event_type'] == 'login_failure'])\n",
    "            unique_users = ip_data['username'].nunique()\n",
    "            time_span = (ip_data['timestamp'].max() - ip_data['timestamp'].min()).total_seconds() / 60\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'ip': ip,\n",
    "                'actual_attacker': False,\n",
    "                'basic_detected': basic_detected,\n",
    "                'ml_detected': ml_detected,\n",
    "                'total_attempts': total_attempts,\n",
    "                'failures': failures,\n",
    "                'failure_rate': failures / total_attempts if total_attempts > 0 else 0,\n",
    "                'unique_users': unique_users,\n",
    "                'time_span_minutes': time_span\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        print(\"üìä DETECTION RESULTS SUMMARY:\")\n",
    "        print(comparison_df[['ip', 'actual_attacker', 'basic_detected', 'ml_detected', 'failures', 'unique_users']].to_string(index=False))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        actual_positives = comparison_df[comparison_df['actual_attacker'] == True]\n",
    "        \n",
    "        # True Positives\n",
    "        basic_tp = len(actual_positives[(actual_positives['basic_detected'] == True)])\n",
    "        ml_tp = len(actual_positives[(actual_positives['ml_detected'] == True)])\n",
    "        \n",
    "        # False Negatives  \n",
    "        basic_fn = len(actual_positives[(actual_positives['basic_detected'] == False)])\n",
    "        ml_fn = len(actual_positives[(actual_positives['ml_detected'] == False)])\n",
    "        \n",
    "        # False Positives\n",
    "        basic_fp = len(comparison_df[(comparison_df['actual_attacker'] == False) & (comparison_df['basic_detected'] == True)])\n",
    "        ml_fp = len(comparison_df[(comparison_df['actual_attacker'] == False) & (comparison_df['ml_detected'] == True)])\n",
    "        \n",
    "        # True Negatives (all other IPs that weren't flagged)\n",
    "        total_unique_ips = auth_df['source_ip'].nunique()\n",
    "        basic_tn = total_unique_ips - basic_tp - basic_fn - basic_fp\n",
    "        ml_tn = total_unique_ips - ml_tp - ml_fn - ml_fp\n",
    "        \n",
    "        print(f\"\\nüìà CONFUSION MATRIX ANALYSIS:\")\n",
    "        print(f\"Total unique IPs in dataset: {total_unique_ips}\")\n",
    "        print(f\"Actual attackers: {len(actual_attackers)}\")\n",
    "        \n",
    "        print(f\"\\nüîç BASIC METHOD:\")\n",
    "        print(f\"  ‚úÖ True Positives (attackers caught): {basic_tp}\")\n",
    "        print(f\"  ‚ùå False Negatives (attackers missed): {basic_fn}\")\n",
    "        print(f\"  ‚ö†Ô∏è  False Positives (innocent flagged): {basic_fp}\")\n",
    "        print(f\"  ‚úÖ True Negatives (innocent ignored): {basic_tn}\")\n",
    "        \n",
    "        print(f\"\\nü§ñ ML METHOD:\")\n",
    "        print(f\"  ‚úÖ True Positives (attackers caught): {ml_tp}\")\n",
    "        print(f\"  ‚ùå False Negatives (attackers missed): {ml_fn}\")\n",
    "        print(f\"  ‚ö†Ô∏è  False Positives (innocent flagged): {ml_fp}\")\n",
    "        print(f\"  ‚úÖ True Negatives (innocent ignored): {ml_tn}\")\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        def calculate_metrics(tp, fp, fn, tn):\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "            return precision, recall, f1, accuracy\n",
    "        \n",
    "        basic_precision, basic_recall, basic_f1, basic_accuracy = calculate_metrics(basic_tp, basic_fp, basic_fn, basic_tn)\n",
    "        ml_precision, ml_recall, ml_f1, ml_accuracy = calculate_metrics(ml_tp, ml_fp, ml_fn, ml_tn)\n",
    "        \n",
    "        print(f\"\\nüéØ PERFORMANCE METRICS:\")\n",
    "        \n",
    "        print(f\"\\nüìä BASIC METHOD SCORES:\")\n",
    "        print(f\"  Precision (when I say attacker, how often am I right?): {basic_precision:.2%}\")\n",
    "        print(f\"  Recall (what % of attackers did I catch?): {basic_recall:.2%}\")\n",
    "        print(f\"  F1-Score (balanced measure): {basic_f1:.3f}\")\n",
    "        print(f\"  Accuracy (overall correctness): {basic_accuracy:.2%}\")\n",
    "        \n",
    "        print(f\"\\nü§ñ ML METHOD SCORES:\")\n",
    "        print(f\"  Precision (when I say attacker, how often am I right?): {ml_precision:.2%}\")\n",
    "        print(f\"  Recall (what % of attackers did I catch?): {ml_recall:.2%}\")\n",
    "        print(f\"  F1-Score (balanced measure): {ml_f1:.3f}\")\n",
    "        print(f\"  Accuracy (overall correctness): {ml_accuracy:.2%}\")\n",
    "        \n",
    "        # Visual comparison\n",
    "        metrics_comparison = pd.DataFrame({\n",
    "            'Method': ['Basic (Excel-style)', 'ML (Behavioral)'],\n",
    "            'Precision': [basic_precision, ml_precision],\n",
    "            'Recall': [basic_recall, ml_recall],\n",
    "            'F1-Score': [basic_f1, ml_f1],\n",
    "            'Accuracy': [basic_accuracy, ml_accuracy]\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nüìä SIDE-BY-SIDE COMPARISON:\")\n",
    "        display(metrics_comparison.round(3))\n",
    "        \n",
    "        # Analyze WHY differences occurred\n",
    "        print(f\"\\nü§î WHY THE DIFFERENCES?\")\n",
    "        \n",
    "        # Look at false positives\n",
    "        if basic_fp > 0 or ml_fp > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  FALSE POSITIVE ANALYSIS:\")\n",
    "            false_pos_ips = comparison_df[comparison_df['actual_attacker'] == False]\n",
    "            \n",
    "            for _, row in false_pos_ips.iterrows():\n",
    "                if row['basic_detected'] or row['ml_detected']:\n",
    "                    print(f\"\\n  üìç {row['ip']} (probably legitimate user with issues):\")\n",
    "                    print(f\"    Basic method flagged: {'Yes' if row['basic_detected'] else 'No'}\")\n",
    "                    print(f\"    ML method flagged: {'Yes' if row['ml_detected'] else 'No'}\")\n",
    "                    print(f\"    Behavior: {row['failures']} failures, {row['unique_users']} users, {row['time_span_minutes']:.1f} min span\")\n",
    "                    \n",
    "                    # Explain why each method flagged it\n",
    "                    if row['basic_detected']:\n",
    "                        print(f\"    üîç Basic flagged because: {row['failures']} failures exceeded threshold\")\n",
    "                    if row['ml_detected']:\n",
    "                        print(f\"    ü§ñ ML flagged because: behavioral pattern differed from normal users\")\n",
    "        \n",
    "        # Look at missed attackers\n",
    "        missed_attackers = comparison_df[(comparison_df['actual_attacker'] == True) & \n",
    "                                    ((comparison_df['basic_detected'] == False) | \n",
    "                                        (comparison_df['ml_detected'] == False))]\n",
    "        \n",
    "        if len(missed_attackers) > 0:\n",
    "            print(f\"\\n‚ùå MISSED ATTACKER ANALYSIS:\")\n",
    "            for _, row in missed_attackers.iterrows():\n",
    "                print(f\"\\n  üö® {row['ip']} (actual attacker that was missed):\")\n",
    "                print(f\"    Basic method missed: {'Yes' if not row['basic_detected'] else 'No'}\")\n",
    "                print(f\"    ML method missed: {'Yes' if not row['ml_detected'] else 'No'}\")\n",
    "                print(f\"    Actual behavior: {row['failures']} failures, {row['unique_users']} users\")\n",
    "                \n",
    "                if not row['basic_detected']:\n",
    "                    print(f\"    üîç Basic missed because: {row['failures']} failures below threshold\")\n",
    "                if not row['ml_detected']:\n",
    "                    print(f\"    ü§ñ ML missed because: behavior appeared 'normal' in aggregate\")\n",
    "        \n",
    "        # Practical recommendations\n",
    "        print(f\"\\nüí° PRACTICAL RECOMMENDATIONS:\")\n",
    "        \n",
    "        if basic_precision > ml_precision:\n",
    "            print(f\"  ‚úÖ Basic method has higher precision - fewer false alarms for analysts\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ ML method has higher precision - fewer false alarms for analysts\")\n",
    "        \n",
    "        if basic_recall > ml_recall:\n",
    "            print(f\"  ‚úÖ Basic method has higher recall - catches more attackers\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ ML method has higher recall - catches more attackers\")\n",
    "        \n",
    "        print(f\"\\nüéØ FOR THIS DATASET, RECOMMEND:\")\n",
    "        \n",
    "        if basic_f1 > ml_f1:\n",
    "            print(f\"  üìä Use BASIC METHOD - better overall balance of precision/recall\")\n",
    "            print(f\"  üïê Faster results: {basic_auth_time:.1f}s vs {ml_auth_time:.1f}s\")\n",
    "            print(f\"  üë• Easier to explain to management and junior analysts\")\n",
    "        else:\n",
    "            print(f\"  ü§ñ Use ML METHOD - better overall balance of precision/recall\")\n",
    "            print(f\"  üîç Better at finding subtle attack patterns\")\n",
    "            print(f\"  üìà Scales better with larger datasets\")\n",
    "        \n",
    "        print(f\"\\nüîÑ HYBRID APPROACH SUGGESTION:\")\n",
    "        print(f\"  1. Use BASIC method for immediate triage (< 30 seconds)\")\n",
    "        print(f\"  2. Use ML method for deeper analysis of suspicious activity\")\n",
    "        print(f\"  3. Combine results: HIGH confidence if both methods agree\")\n",
    "        \n",
    "        return comparison_df, metrics_comparison\n",
    "\n",
    "    # Run the detailed comparison\n",
    "    comparison_results, metrics_df = detailed_method_comparison()\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## üìà **Visualization: Method Performance Comparison**\n",
    "\n",
    "    # %%\n",
    "    def visualize_method_comparison(metrics_df):\n",
    "        \"\"\"Create visualizations comparing the two methods\"\"\"\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Excel-style vs ML Method Comparison', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        methods = metrics_df['Method']\n",
    "        \n",
    "        # Precision comparison\n",
    "        ax1.bar(methods, metrics_df['Precision'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax1.set_title('Precision: When I say \"attacker\", how often am I right?')\n",
    "        ax1.set_ylabel('Precision Score')\n",
    "        ax1.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['Precision']):\n",
    "            ax1.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "        \n",
    "        # Recall comparison  \n",
    "        ax2.bar(methods, metrics_df['Recall'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax2.set_title('Recall: What % of attackers did I catch?')\n",
    "        ax2.set_ylabel('Recall Score')\n",
    "        ax2.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['Recall']):\n",
    "            ax2.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "        \n",
    "        # F1-Score comparison\n",
    "        ax3.bar(methods, metrics_df['F1-Score'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax3.set_title('F1-Score: Balanced measure of performance')\n",
    "        ax3.set_ylabel('F1-Score')\n",
    "        ax3.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['F1-Score']):\n",
    "            ax3.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "        \n",
    "        # Accuracy comparison\n",
    "        ax4.bar(methods, metrics_df['Accuracy'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax4.set_title('Accuracy: Overall correctness')\n",
    "        ax4.set_ylabel('Accuracy Score') \n",
    "        ax4.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['Accuracy']):\n",
    "            ax4.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create a radar chart for overall comparison\n",
    "        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))\n",
    "        \n",
    "        categories = ['Precision', 'Recall', 'F1-Score', 'Accuracy']\n",
    "        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Complete the circle\n",
    "        \n",
    "        # Basic method\n",
    "        basic_values = metrics_df.iloc[0][1:].tolist()\n",
    "        basic_values += basic_values[:1]\n",
    "        ax.plot(angles, basic_values, 'o-', linewidth=2, label='Excel-style (Basic)', color='#3498db')\n",
    "        ax.fill(angles, basic_values, alpha=0.25, color='#3498db')\n",
    "        \n",
    "        # ML method  \n",
    "        ml_values = metrics_df.iloc[1][1:].tolist()\n",
    "        ml_values += ml_values[:1]\n",
    "        ax.plot(angles, ml_values, 'o-', linewidth=2, label='ML (Behavioral)', color='#e74c3c')\n",
    "        ax.fill(angles, ml_values, alpha=0.25, color='#e74c3c')\n",
    "        \n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(categories)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_title('Overall Method Performance Comparison\\n(Larger area = Better performance)', \n",
    "                    pad=20, fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "        ax.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Create the visualizations\n",
    "    visualize_method_comparison(metrics_df)\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## üéì **Key Takeaways: When to Use Each Method**\n",
    "\n",
    "    # %%\n",
    "    def print_decision_guide():\n",
    "        \"\"\"Print a practical guide for choosing between methods\"\"\"\n",
    "        \n",
    "        print(\"üéì DECISION GUIDE: EXCEL vs ML FOR AUTHENTICATION ANALYSIS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(\"\\nüîç USE EXCEL/BASIC METHOD WHEN:\")\n",
    "        print(\"  ‚úÖ You need results RIGHT NOW (active incident)\")\n",
    "        print(\"  ‚úÖ Your team is not comfortable with Python/ML\")\n",
    "        print(\"  ‚úÖ You have clear, simple thresholds (>50 failed logins = investigate)\")\n",
    "        print(\"  ‚úÖ Dataset is small (<10K authentication events)\")\n",
    "        print(\"  ‚úÖ Attackers are 'noisy' (many failed attempts)\")\n",
    "        print(\"  ‚úÖ You need to explain results to management\")\n",
    "        \n",
    "        print(f\"  ‚è±Ô∏è  Time to results: {basic_auth_time:.1f} seconds\")\n",
    "        print(f\"  üéØ Best for: Incident response, SOC triage, management reporting\")\n",
    "        \n",
    "        print(\"\\nü§ñ USE ML/BEHAVIORAL METHOD WHEN:\")\n",
    "        print(\"  ‚úÖ You have time for deeper analysis (threat hunting)\")\n",
    "        print(\"  ‚úÖ Your team has ML/Python skills\")\n",
    "        print(\"  ‚úÖ Attackers might be sophisticated (low-and-slow attacks)\")\n",
    "        print(\"  ‚úÖ Dataset is large (>10K authentication events)\")\n",
    "        print(\"  ‚úÖ You want to find subtle patterns\")\n",
    "        print(\"  ‚úÖ You're building automated detection systems\")\n",
    "        \n",
    "        print(f\"  ‚è±Ô∏è  Time to results: {ml_auth_time:.1f} seconds\")\n",
    "        print(f\"  üéØ Best for: Threat hunting, advanced persistent threats, automation\")\n",
    "        \n",
    "        print(\"\\nüîÑ HYBRID APPROACH (RECOMMENDED):\")\n",
    "        print(\"  1Ô∏è‚É£  Start with BASIC method for quick wins\")\n",
    "        print(\"  2Ô∏è‚É£  Use ML method to double-check and find subtle threats\")\n",
    "        print(\"  3Ô∏è‚É£  Investigate anything flagged by BOTH methods first\")\n",
    "        print(\"  4Ô∏è‚É£  Use ML findings to improve your basic thresholds\")\n",
    "        \n",
    "        print(\"\\nüìä REAL-WORLD WORKFLOW:\")\n",
    "        print(\"  üö® Incident Response (0-30 min): Basic method only\")\n",
    "        print(\"  üîç Daily Threat Hunting (30+ min): ML method\")\n",
    "        print(\"  üìà Weekly Reviews: Compare both methods' findings\")\n",
    "        print(\"  üéØ Tuning: Use ML insights to improve basic rules\")\n",
    "        \n",
    "        print(\"\\n‚ö†Ô∏è  REMEMBER:\")\n",
    "        print(\"  ‚Ä¢ No method is perfect - always validate findings\")\n",
    "        print(\"  ‚Ä¢ Context matters more than algorithms\")\n",
    "        print(\"  ‚Ä¢ The best method is the one your team will actually use\")\n",
    "        print(\"  ‚Ä¢ Simple methods that work beat complex methods that don't\")\n",
    "\n",
    "def print_decision_guide():\n",
    "    \"\"\"Compare basic vs ML methods for authentication analysis\"\"\"\n",
    "        \n",
    "    print(\"üìä METHOD COMPARISON - MODULE 2\")\n",
    "    print(\"=\" * 50)\n",
    "        \n",
    "    # Known attack sources from our data generation\n",
    "    actual_attackers = ['203.0.113.15', '198.51.100.42', '192.0.2.123', '185.199.108.153']\n",
    "        \n",
    "    # Basic method results\n",
    "    basic_attackers = basic_auth_results['potential_attackers'].index.tolist()\n",
    "        \n",
    "    # ML method results  \n",
    "    ml_attackers = ml_auth_results['outlier_ips'].index.tolist()\n",
    "        \n",
    "    print(f\"üéØ ACTUAL ATTACK IPs: {actual_attackers}\")\n",
    "    print(f\"üîç BASIC METHOD found: {basic_attackers}\")\n",
    "    print(f\"ü§ñ ML METHOD found: {ml_attackers}\")\n",
    "        \n",
    "    # Calculate detection accuracy\n",
    "    basic_detected = len(set(basic_attackers) & set(actual_attackers))\n",
    "    ml_detected = len(set(ml_attackers) & set(actual_attackers))\n",
    "        \n",
    "    basic_false_positives = len(set(basic_attackers) - set(actual_attackers))\n",
    "    ml_false_positives = len(set(ml_attackers) - set(actual_attackers))\n",
    "        \n",
    "    print(f\"\\nüìà DETECTION RESULTS:\")\n",
    "    print(f\"   Basic method: {basic_detected}/{len(actual_attackers)} correct ({basic_detected/len(actual_attackers)*100:.0f}%)\")\n",
    "    print(f\"   ML method: {ml_detected}/{len(actual_attackers)} correct ({ml_detected/len(actual_attackers)*100:.0f}%)\")\n",
    "        \n",
    "    print(f\"\\n‚ùå FALSE POSITIVES:\")\n",
    "    print(f\"   Basic method: {basic_false_positives} false alarms\")\n",
    "    print(f\"   ML method: {ml_false_positives} false alarms\")\n",
    "        \n",
    "    print(f\"\\n‚è±Ô∏è TIMING COMPARISON:\")\n",
    "    print(f\"   Basic method: {basic_auth_time:.2f} seconds\")\n",
    "    print(f\"   ML method: {ml_auth_time:.2f} seconds\")\n",
    "    print(f\"   Speed difference: {ml_auth_time/basic_auth_time:.1f}x slower\")\n",
    "        \n",
    "    # Detailed analysis\n",
    "    print(f\"\\nüîç DETAILED ANALYSIS:\")\n",
    "        \n",
    "    if basic_false_positives > 0:\n",
    "        false_basic = set(basic_attackers) - set(actual_attackers)\n",
    "        print(f\"   Basic false positives: {list(false_basic)}\")\n",
    "        for fp_ip in false_basic:\n",
    "            fp_data = auth_df[auth_df['source_ip'] == fp_ip]\n",
    "            failures = len(fp_data[fp_data['event_type'] == 'login_failure'])\n",
    "            print(f\"     {fp_ip}: {failures} failed logins (legitimate user with password issues?)\")\n",
    "        \n",
    "    if ml_false_positives > 0:\n",
    "        false_ml = set(ml_attackers) - set(actual_attackers)\n",
    "        print(f\"   ML false positives: {list(false_ml)}\")\n",
    "        \n",
    "    print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(\"‚úÖ Basic method strengths:\")\n",
    "    print(\"   ‚Ä¢ Fast results for known attack patterns\")\n",
    "    print(\"   ‚Ä¢ Easy to explain to stakeholders\")\n",
    "    print(\"   ‚Ä¢ Good for simple threshold-based detection\")\n",
    "        \n",
    "    print(\"\\n‚úÖ ML method strengths:\")\n",
    "    print(\"   ‚Ä¢ Detects subtle behavioral anomalies\")\n",
    "    print(\"   ‚Ä¢ Better at finding sophisticated attacks\")\n",
    "    print(\"   ‚Ä¢ Can adapt to new attack patterns\")\n",
    "        \n",
    "    print(\"\\nüö® INCIDENT RESPONSE RECOMMENDATION:\")\n",
    "    if basic_detected == len(actual_attackers) and basic_false_positives == 0:\n",
    "        print(\"   Use BASIC method: Perfect detection with fast results!\")\n",
    "    elif ml_detected > basic_detected:\n",
    "        print(\"   Use ML method: Better detection of sophisticated attacks\")\n",
    "    else:\n",
    "        print(\"   Use HYBRID approach: Basic for triage, ML for deep analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_methods_module2()\n",
    "print_decision_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code used to generate the datasets used in these modules may be found below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_traffic_data(num_records=10000):\n",
    "    \"\"\"Generate realistic network traffic data with hidden anomalies\"\"\"\n",
    "    \n",
    "    # Normal traffic patterns\n",
    "    normal_sources = [f\"192.168.1.{i}\" for i in range(10, 100)]\n",
    "    normal_destinations = [f\"10.0.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    common_ports = [80, 443, 22, 25, 53, 110, 143, 993, 995]\n",
    "    \n",
    "    # Generate timestamps over last 24 hours\n",
    "    start_time = dt.now() - timedelta(hours=24)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Normal traffic (90% of data)\n",
    "    for _ in range(int(num_records * 0.90)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        source = random.choice(normal_sources)\n",
    "        destination = random.choice(normal_destinations)\n",
    "        port = random.choice(common_ports)\n",
    "        bytes_sent = random.randint(64, 1500)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    # Suspicious traffic (10% of data) - More obvious for Excel detection\n",
    "    suspicious_ips = ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
    "    suspicious_ports = [1337, 4444, 8080, 9999, 31337]\n",
    "    \n",
    "    for _ in range(int(num_records * 0.10)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        \n",
    "        if random.random() < 0.4:  # External suspicious IP\n",
    "            source = random.choice(suspicious_ips)\n",
    "            destination = random.choice(normal_destinations)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(5000, 50000)  # Much larger transfers\n",
    "        else:  # Internal lateral movement\n",
    "            source = random.choice(normal_sources)\n",
    "            destination = random.choice(normal_sources)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(2000, 10000)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.sample(frac=1).reset_index(drop=True)  # Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "traffic_df = generate_network_traffic_data(500000)\n",
    "print(f\"üìä Generated {len(traffic_df):,} network traffic records\")\n",
    "print(f\"üìÖ Time range: {traffic_df['timestamp'].min()} to {traffic_df['timestamp'].max()}\")\n",
    "\n",
    "# Save to CSV for Excel analysis\n",
    "traffic_df.to_csv(f\"{DATA_DIR}/network_traffic.csv\", index=False)\n",
    "print(\"üíæ Saved to network_traffic.csv\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(traffic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auth_logs(num_records=10000):\n",
    "    \"\"\"Generate authentication logs with brute force attacks\"\"\"\n",
    "    \n",
    "    # Normal users\n",
    "    normal_users = [f\"user{i:03d}\" for i in range(1, 201)]\n",
    "    normal_sources = [f\"192.168.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    \n",
    "    # Attackers\n",
    "    attack_sources = ['203.0.113.15', '198.51.100.42', '192.0.2.123']\n",
    "    attack_targets = ['admin', 'administrator', 'root', 'service', 'guest']\n",
    "    \n",
    "    data = []\n",
    "    start_time = dt.now() - timedelta(hours=6)\n",
    "    \n",
    "    # Normal successful logins (80%)\n",
    "    for _ in range(int(num_records * 0.8)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 21600))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_success',\n",
    "            'service': 'ssh'\n",
    "        })\n",
    "    \n",
    "    # Normal failed logins (15%)\n",
    "    for _ in range(int(num_records * 0.15)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 21600))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_failure',\n",
    "            'service': 'ssh'\n",
    "        })\n",
    "    \n",
    "    # Brute force attacks (5%)\n",
    "    for attacker_ip in attack_sources:\n",
    "        attack_start = start_time + timedelta(hours=random.randint(1, 4))\n",
    "        \n",
    "        # Generate rapid-fire attempts\n",
    "        for i in range(random.randint(50, 200)):\n",
    "            timestamp = attack_start + timedelta(seconds=i * random.randint(1, 5))\n",
    "            user = random.choice(attack_targets + normal_users[:20])\n",
    "            \n",
    "            data.append({\n",
    "                'timestamp': timestamp,\n",
    "                'username': user,\n",
    "                'source_ip': attacker_ip,\n",
    "                'event_type': 'login_failure',\n",
    "                'service': 'ssh'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def basic_auth_analysis(df):\n",
    "    \"\"\"Basic authentication analysis\"\"\"\n",
    "    \n",
    "    print(\"=== BASIC AUTH ANALYSIS ===\")\n",
    "    \n",
    "    # Failed login attempts by IP\n",
    "    failed_logins = df[df['event_type'] == 'login_failure']\n",
    "    ip_failures = failed_logins.groupby('source_ip').size().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nTop IPs by failed login attempts:\")\n",
    "    print(ip_failures.head(10))\n",
    "    \n",
    "    # Brute force detection (simple threshold)\n",
    "    brute_force_threshold = 20\n",
    "    potential_attackers = ip_failures[ip_failures >= brute_force_threshold]\n",
    "    \n",
    "    print(f\"\\nPotential brute force attackers (>={brute_force_threshold} failures):\")\n",
    "    for ip, count in potential_attackers.items():\n",
    "        ip_data = failed_logins[failed_logins['source_ip'] == ip]\n",
    "        unique_users = ip_data['username'].nunique()\n",
    "        time_span = (ip_data['timestamp'].max() - ip_data['timestamp'].min()).total_seconds() / 60\n",
    "        print(f\"  {ip}: {count} failures, {unique_users} users, {time_span:.1f} minutes\")\n",
    "    \n",
    "    return potential_attackers\n",
    "\n",
    "def ml_auth_analysis(df):\n",
    "    \"\"\"ML-based authentication analysis\"\"\"\n",
    "    \n",
    "    print(\"\\n=== ML AUTH ANALYSIS ===\")\n",
    "    \n",
    "    # Create time-based features\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    \n",
    "    # Aggregate by IP and time window (5-minute windows)\n",
    "    df['time_window'] = df['timestamp'].dt.floor('5min')\n",
    "    \n",
    "    features = df.groupby(['source_ip', 'time_window']).agg({\n",
    "        'username': 'nunique',\n",
    "        'event_type': lambda x: (x == 'login_failure').sum(),\n",
    "        'timestamp': 'count'\n",
    "    }).rename(columns={\n",
    "        'username': 'unique_users',\n",
    "        'event_type': 'failures',\n",
    "        'timestamp': 'total_attempts'\n",
    "    })\n",
    "    \n",
    "    # Calculate failure rate\n",
    "    features['failure_rate'] = features['failures'] / features['total_attempts']\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    # Apply clustering to find unusual patterns\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Use DBSCAN to find clusters\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    clusters = dbscan.fit_predict(features_scaled)\n",
    "    \n",
    "    # Analyze outliers (cluster -1)\n",
    "    outliers = features[clusters == -1]\n",
    "    \n",
    "    print(f\"\\nOutlier authentication patterns detected: {len(outliers)}\")\n",
    "    \n",
    "    # Group outliers by IP\n",
    "    for ip in outliers.index.get_level_values('source_ip').unique()[:5]:\n",
    "        ip_outliers = outliers[outliers.index.get_level_values('source_ip') == ip]\n",
    "        print(f\"\\n{ip}:\")\n",
    "        print(f\"  Outlier time windows: {len(ip_outliers)}\")\n",
    "        print(f\"  Max failures in 5min: {ip_outliers['failures'].max()}\")\n",
    "        print(f\"  Max unique users in 5min: {ip_outliers['unique_users'].max()}\")\n",
    "        print(f\"  Max failure rate: {ip_outliers['failure_rate'].max():.2f}\")\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_df = generate_auth_logs(10000)\n",
    "print(f\"üìä Generated {len(auth_df):,} authentication records\")\n",
    "print(f\"üìÖ Time range: {auth_df['timestamp'].min()} to {auth_df['timestamp'].max()}\")\n",
    "\n",
    "# Save to CSV\n",
    "auth_df.to_csv('auth_logs.csv', index=False)\n",
    "print(\"üíæ Saved to auth_logs.csv\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(auth_df.head())\n",
    "\n",
    "# Quick overview\n",
    "print(f\"\\nüìà Event breakdown:\")\n",
    "print(auth_df['event_type'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
