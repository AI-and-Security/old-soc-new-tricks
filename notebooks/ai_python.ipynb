{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Security Data Analysis Workshop\n",
    "## Blue Team Focus: When to use AI/ML vs Basic Methods\n",
    "\n",
    "This notebook demonstrates when to use simple statistical methods vs machine learning \n",
    "for cybersecurity analysis. Each module compares both approaches with realistic datasets.\n",
    "\n",
    "## Setup and Imports ##"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Colab\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "if is_colab:\n",
    "    %pip install -r \"https://raw.githubusercontent.com/AI-and-Security/old-soc-new-tricks/main/requirements-colab.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Using data directory: ../data\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5afb9b7 (Cleared outputs)
   "source": [
    "# Set up data directory based on environment\n",
    "if is_colab:\n",
=======
    "# Check if running in Colab\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "# Set up data directory based on environment\n",
    "if is_colab():\n",
>>>>>>> main
    "    # Create data directory in Colab\n",
    "    import os\n",
    "    DATA_DIR = \"./data\"\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    \n",
    "    # Download data files from GitHub repository\n",
    "    !git clone https://github.com/AI-and-Security/old-soc-new-tricks.git temp_repo\n",
    "    !mkdir -p {DATA_DIR}\n",
    "    !cp -r temp_repo/data/* {DATA_DIR}/\n",
    "    !rm -rf temp_repo\n",
    "    print(\"‚úÖ Data files downloaded to Colab environment\")\n",
    "else:\n",
    "    # Local environment - use relative path\n",
    "    DATA_DIR = \"../data\"\n",
    "\n",
    "print(f\"üìÇ Using data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": null,
>>>>>>> 5afb9b7 (Cleared outputs)
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt, timedelta\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": null,
>>>>>>> 5afb9b7 (Cleared outputs)
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": null,
>>>>>>> 5afb9b7 (Cleared outputs)
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
>>>>>>> main
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# Lesson 1: The Overwhelmed SOC Analyst\n",
    "# **Persona**: Junior analyst drowning in thousands of alerts/entries in traffic logs. Note: Applicable to both threat hunters and SOC analysts. SOC does it after an alert to determine ‚Äúinvestigation worthy‚Äù or not, threat hunters find the suspicious activity proactively.\n",
    "\n",
    "# \n",
    "# **Scenario**: You have network traffic logs and need to quickly identify suspicious activity.\n",
    "# \n",
    "# **Question**: Should you use Excel pivot tables or machine learning?\n",
    "\n",
    "# 1.1 Import Network Traffic Dataset\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = pd.read_csv(f\"{DATA_DIR}/network_traffic.csv\")\n",
    "traffic_df['timestamp'] = pd.to_datetime(traffic_df['timestamp'])\n",
=======
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Sample of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source_ip</th>\n",
       "      <th>destination_ip</th>\n",
       "      <th>destination_port</th>\n",
       "      <th>bytes</th>\n",
       "      <th>protocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-07 13:28:04</td>\n",
       "      <td>192.168.1.70</td>\n",
       "      <td>10.0.4.29</td>\n",
       "      <td>80</td>\n",
       "      <td>593</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-06 20:16:02</td>\n",
       "      <td>192.168.1.86</td>\n",
       "      <td>10.0.2.19</td>\n",
       "      <td>110</td>\n",
       "      <td>416</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-06 18:30:01</td>\n",
       "      <td>192.168.1.30</td>\n",
       "      <td>10.0.1.44</td>\n",
       "      <td>110</td>\n",
       "      <td>1358</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-06 18:37:56</td>\n",
       "      <td>192.168.1.44</td>\n",
       "      <td>10.0.3.30</td>\n",
       "      <td>25</td>\n",
       "      <td>93</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-07 10:06:04</td>\n",
       "      <td>192.168.1.98</td>\n",
       "      <td>10.0.1.40</td>\n",
       "      <td>995</td>\n",
       "      <td>1251</td>\n",
       "      <td>TCP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp     source_ip destination_ip  destination_port  bytes  \\\n",
       "0  2025-08-07 13:28:04  192.168.1.70      10.0.4.29                80    593   \n",
       "1  2025-08-06 20:16:02  192.168.1.86      10.0.2.19               110    416   \n",
       "2  2025-08-06 18:30:01  192.168.1.30      10.0.1.44               110   1358   \n",
       "3  2025-08-06 18:37:56  192.168.1.44      10.0.3.30                25     93   \n",
       "4  2025-08-07 10:06:04  192.168.1.98      10.0.1.40               995   1251   \n",
       "\n",
       "  protocol  \n",
       "0      TCP  \n",
       "1      TCP  \n",
       "2      TCP  \n",
       "3      TCP  \n",
       "4      TCP  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5afb9b7 (Cleared outputs)
   "source": [
    "traffic_df = pd.read_csv(f\"{DATA_DIR}/network_traffic.csv\")\n",
>>>>>>> main
    "\n",
    "# Display sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(traffic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Basic Analysis (Excel-Style in Python)\n",
    "**Let's generate some basic statistics! You can use a tool like Excel for this**\n",
    "**type of analysis, but you can also do this using python and pandas!**\n",
    "\n",
    "Let's look for:\n",
    "- Top talkers by bytes sent\n",
    "- Unusual ports (simple frequency analysis)\n",
    "- Large transfers (95th percentile threshold)\n",
    "- Quick suspicious IP identification based on a pre-determined list of \"suspicious\" IPs\n",
    "\n",
    "Pros:\n",
    "- Very quick analysis\n",
    "- Summary statistics\n",
    "- Explainable!\n",
    "\n",
    "Cons:\n",
    "- No insight into complex behavior patterns\n",
    "- Must pre-determine statistics you want to examine\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 48,
>>>>>>> main
=======
   "execution_count": null,
>>>>>>> 5afb9b7 (Cleared outputs)
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_traffic_analysis(df):\n",
    "    \"\"\"Basic analysis that mirrors Excel pivot tables and filters\"\"\"\n",
    "    \n",
    "    print(\"üîé BASIC ANALYSIS (Excel-style approach)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analysis 1: Top talkers by bytes sent\n",
    "    print(\"\\nüìà TOP 10 SOURCES BY TOTAL BYTES:\")\n",
    "    top_sources = df.groupby('source_ip')['bytes'].agg(['sum', 'count', 'mean']).round(2)\n",
    "    top_sources.columns = ['total_bytes', 'connections', 'avg_bytes']\n",
    "    top_sources = top_sources.sort_values('total_bytes', ascending=False)\n",
    "    print(top_sources.head(10))\n",
    "    \n",
    "    # Analysis 2: Unusual ports (simple frequency analysis)\n",
    "    print(\"\\nüîç UNUSUAL PORTS (used ‚â§ 5 times):\")\n",
    "    port_counts = df['destination_port'].value_counts()\n",
    "    unusual_ports = port_counts[port_counts <= 5]\n",
    "    print(f\"Found {len(unusual_ports)} unusual ports:\")\n",
    "    print(unusual_ports.head(10))\n",
    "    \n",
    "    # Analysis 3: Large transfers (95th percentile threshold)\n",
    "    threshold = df['bytes'].quantile(0.95)\n",
    "    large_transfers = df[df['bytes'] > threshold]\n",
    "    print(f\"\\nüìä LARGE TRANSFERS (> {threshold:,.0f} bytes):\")\n",
    "    print(f\"Found {len(large_transfers)} large transfers\")\n",
    "    \n",
    "    large_by_source = large_transfers.groupby('source_ip').agg({\n",
    "        'bytes': ['count', 'sum', 'max'],\n",
    "        'destination_port': lambda x: list(x.unique())\n",
    "    })\n",
    "    large_by_source.columns = ['transfer_count', 'total_bytes', 'max_bytes', 'ports_used']\n",
    "    print(large_by_source.head())\n",
    "    \n",
    "    # Quick suspicious IP identification\n",
    "    suspicious_keywords = ['185.', '194.', '91.', '203.']\n",
    "    external_ips = df[df['source_ip'].str.contains('|'.join(suspicious_keywords), na=False)]\n",
    "    \n",
    "    print(f\"\\nüö® EXTERNAL SOURCE IPs:\")\n",
    "    if len(external_ips) > 0:\n",
    "        ext_summary = external_ips.groupby('source_ip').agg({\n",
    "            'bytes': ['count', 'sum'],\n",
    "            'destination_port': lambda x: list(x.unique())\n",
    "        })\n",
    "        ext_summary.columns = ['connections', 'total_bytes', 'ports_used']\n",
    "        print(ext_summary)\n",
    "    else:\n",
    "        print(\"No external IPs detected with basic pattern matching\")\n",
    "    \n",
    "    return {\n",
    "        'top_sources': top_sources,\n",
    "        'unusual_ports': unusual_ports,\n",
    "        'large_transfers': large_transfers,\n",
    "        'external_ips': external_ips\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé BASIC ANALYSIS (Excel-style approach)\n",
      "==================================================\n",
      "\n",
      "üìà TOP 10 SOURCES BY TOTAL BYTES:\n",
      "                total_bytes  connections  avg_bytes\n",
      "source_ip                                          \n",
      "91.234.99.12      186521374         6779   27514.59\n",
      "194.233.164.24    183246579         6665   27493.86\n",
      "185.220.70.43     182402315         6670   27346.67\n",
      "192.168.1.93        6146509         5398    1138.66\n",
      "192.168.1.68        6116451         5411    1130.37\n",
      "192.168.1.25        6103727         5395    1131.37\n",
      "192.168.1.29        6091999         5377    1132.97\n",
      "192.168.1.53        6074514         5482    1108.08\n",
      "192.168.1.59        6072127         5357    1133.49\n",
      "192.168.1.10        6066406         5387    1126.12\n",
      "\n",
      "üîç UNUSUAL PORTS (used ‚â§ 5 times):\n",
      "Found 0 unusual ports:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "üìä LARGE TRANSFERS (> 8,311 bytes):\n",
      "Found 24996 large transfers\n",
      "               transfer_count  total_bytes  max_bytes  \\\n",
      "source_ip                                               \n",
      "185.220.70.43            6141    178900410      49999   \n",
      "192.168.1.10               81       741877       9977   \n",
      "192.168.1.11               85       782152       9970   \n",
      "192.168.1.12               68       622347       9974   \n",
      "192.168.1.13               74       679755       9978   \n",
      "\n",
      "                                    ports_used  \n",
      "source_ip                                       \n",
      "185.220.70.43  [4444, 9999, 1337, 31337, 8080]  \n",
      "192.168.1.10   [31337, 1337, 9999, 4444, 8080]  \n",
      "192.168.1.11   [1337, 4444, 31337, 9999, 8080]  \n",
      "192.168.1.12   [31337, 4444, 9999, 8080, 1337]  \n",
      "192.168.1.13   [4444, 31337, 9999, 8080, 1337]  \n",
      "\n",
      "üö® EXTERNAL SOURCE IPs:\n",
      "                connections  total_bytes                       ports_used\n",
      "source_ip                                                                \n",
      "185.220.70.43          6670    182402315  [4444, 9999, 1337, 31337, 8080]\n",
      "194.233.164.24         6665    183246579  [8080, 1337, 4444, 31337, 9999]\n",
      "91.234.99.12           6779    186521374  [9999, 4444, 31337, 8080, 1337]\n",
      "\n",
      "‚è±Ô∏è Basic analysis completed in 0.38 seconds\n"
     ]
    }
   ],
>>>>>>> main
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5afb9b7 (Cleared outputs)
   "source": [
    "# Time the analysis\n",
    "start_time = time.time()\n",
    "basic_results = basic_traffic_analysis(traffic_df)\n",
    "basic_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Basic analysis completed in {basic_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Machine Learning Analysis\n",
    "**We will use an isolation forest to identify anomalies in this dataset.**\n",
    "\n",
    "**What is an isolation forest, and why would we use this type of algorithm?**\n",
    "The isolation forest algorithm is one ML algorithm which answers the question,\n",
    "\"Can you show me data points that are anomalous?\" This algorithm is one example \n",
    "of a machine learning algorithm that is relatively efficient and low memory, \n",
    "which makes it a great algorithm for large datasets. \n",
    "\n",
    "**How This Applies to Security Data:**\n",
    "Imagine you have 10,000 network connections. Most are normal:\n",
    "\n",
    "Employee checking email\n",
    "Someone browsing CNN.com\n",
    "Automatic software updates\n",
    "\n",
    "But one connection is weird:\n",
    "\n",
    "Coming from an IP in North Korea\n",
    "Downloading 50GB of customer data\n",
    "At 3 AM on a Sunday\n",
    "\n",
    "The weird connection is easy to isolate with just a few \"cuts\":\n",
    "\n",
    "- \"Is the IP from a normal location?\" ‚Üí No (isolates 90% of traffic)\n",
    "\n",
    "- \"Is the data volume normal?\" ‚Üí No (isolates 95% of remaining)\n",
    "\n",
    "- \"Is the time normal?\" ‚Üí No (isolated!)\n",
    "\n",
    "The normal connections are hard to isolate - they blend in with thousands of others.\n",
    "The \"Forest\" Part:\n",
    "We don't just build one \"decision tree\" - we build many (a forest!). Each tree asks different random questions:\n",
    "\n",
    "- Tree 1: \"IP location?\" ‚Üí \"Data volume?\" ‚Üí \"Time of day?\"\n",
    "\n",
    "- Tree 2: \"Port number?\" ‚Üí \"Duration?\" ‚Üí \"User type?\"\n",
    "\n",
    "- Tree 3: \"Protocol?\" ‚Üí \"Frequency?\" ‚Üí \"Destination?\"\n",
    "\n",
    "If something is truly anomalous, it should be easy to isolate in MOST trees. If something only looks weird in one tree, it's probably just normal variation. This algorithm might be a good one for some use cases because...\n",
    "\n",
    "‚úÖ No Training Required: You don't need examples of \"good\" vs \"bad\" - it just finds things that don't fit the pattern.\n",
    "\n",
    "‚úÖ Finds Unknown Threats: Traditional security tools look for known bad stuff. Isolation Forest finds anything that's weird, including brand-new attacks.\n",
    "\n",
    "‚úÖ Fast & Scalable: Each tree is simple, so you can analyze millions of records quickly.\n",
    "\n",
    "Pros:\n",
    "- Allows you to discover and examine complex behavior patterns\n",
    "- Incorporates context into your analysis\n",
    "- Depending on the features extracted, can be explainable.\n",
    "\n",
    "Cons:\n",
    "- The performance of the Isolation Forest algorithm is highly dependent on the selection of its parameters.  \n",
    "- More complex algorithm-- caution should be used if you don't know how it works!\n",
    "- Depending on the features, can be hard to explain!\n",
    "- May produce false positives/false negatives"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 62,
>>>>>>> main
=======
   "execution_count": null,
>>>>>>> 5afb9b7 (Cleared outputs)
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_traffic_analysis(df):\n",
    "    \"\"\"ML-based anomaly detection for network traffic\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ MACHINE LEARNING ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Feature engineering: Create behavioral profiles per source IP\n",
    "    print(\"\\nüîß Creating behavioral features...\")\n",
    "    \n",
    "    features = df.groupby('source_ip').agg({\n",
    "        'bytes': ['sum', 'mean', 'std', 'max', 'count'],\n",
    "        'destination_ip': 'nunique',\n",
    "        'destination_port': ['nunique', lambda x: list(x)],\n",
    "        'timestamp': lambda x: (x.max() - x.min()).total_seconds() / 3600  # session duration in hours\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    features.columns = ['bytes_sum', 'bytes_mean', 'bytes_std', 'bytes_max', 'connection_count', \n",
    "                       'unique_destinations', 'unique_ports', 'ports_list', 'session_duration_hours']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    features['bytes_std'] = features['bytes_std'].fillna(0)\n",
    "    \n",
    "    # Add derived features\n",
    "    features['avg_bytes_per_connection'] = features['bytes_sum'] / features['connection_count']\n",
    "    features['port_diversity'] = features['unique_ports'] / features['connection_count']\n",
    "    \n",
    "    # Check for suspicious ports based on pre-determined list of ports\n",
    "    suspicious_ports = [1337, 4444, 8080, 9999, 31337, 6666]\n",
    "    features['has_suspicious_ports'] = features['ports_list'].apply(\n",
    "        lambda ports: any(port in suspicious_ports for port in ports)\n",
    "    ).astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Created features for {len(features)} unique source IPs\")\n",
    "    print(\"\\nüìä Feature summary:\")\n",
    "    display(features[['bytes_sum', 'connection_count', 'unique_destinations', 'unique_ports', 'has_suspicious_ports']].describe())\n",
    "    \n",
    "    # Prepare features for ML (exclude non-numeric columns)\n",
    "    ml_features = features.drop(['ports_list'], axis=1)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(ml_features)\n",
    "    \n",
    "    # Apply Isolation Forest for anomaly detection\n",
    "    print(\"\\nüîç Applying Isolation Forest anomaly detection...\")\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42, n_estimators=100)\n",
    "    anomaly_labels = iso_forest.fit_predict(features_scaled)\n",
    "    \n",
    "    # Get anomaly scores\n",
    "    anomaly_scores = iso_forest.decision_function(features_scaled)\n",
    "    \n",
    "    # Add results back to features\n",
    "    features['anomaly_label'] = anomaly_labels\n",
    "    features['anomaly_score'] = anomaly_scores\n",
    "    \n",
    "    # Analyze anomalies\n",
    "    anomalies = features[features['anomaly_label'] == -1].sort_values('anomaly_score')\n",
    "    \n",
    "    print(f\"\\nüö® ANOMALOUS SOURCE IPs DETECTED: {len(anomalies)}\")\n",
    "    print(\"\\nTop 5 most anomalous IPs:\")\n",
    "    \n",
    "    for i, (ip, row) in enumerate(anomalies.head().iterrows()):\n",
    "        print(f\"\\n{i+1}. {ip} (anomaly score: {row['anomaly_score']:.3f})\")\n",
    "        print(f\"   üìä Total bytes: {row['bytes_sum']:,}\")\n",
    "        print(f\"   üîó Connections: {row['connection_count']}\")\n",
    "        print(f\"   üéØ Unique destinations: {row['unique_destinations']}\")\n",
    "        print(f\"   üîå Unique ports: {row['unique_ports']}\")\n",
    "        print(f\"   ‚ö†Ô∏è  Has suspicious ports: {'Yes' if row['has_suspicious_ports'] else 'No'}\")\n",
    "        print(f\"   üïê Session duration: {row['session_duration_hours']:.1f} hours\")\n",
    "        \n",
    "        # Show actual ports used\n",
    "        actual_data = df[df['source_ip'] == ip]\n",
    "        ports_used = actual_data['destination_port'].value_counts().head(5)\n",
    "        cast_ports = {key: int(value) for key, value in dict(ports_used).items()}\n",
    "        print(f\"   üîå Top ports: {cast_ports}\")\n",
    "    \n",
    "    return {\n",
    "        'features': features,\n",
    "        'anomalies': anomalies,\n",
    "        'model': iso_forest,\n",
    "        'scaler': scaler\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ MACHINE LEARNING ANALYSIS\n",
      "==================================================\n",
      "\n",
      "üîß Creating behavioral features...\n",
      "‚úÖ Created features for 93 unique source IPs\n",
      "\n",
      "üìä Feature summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bytes_sum</th>\n",
       "      <th>connection_count</th>\n",
       "      <th>unique_destinations</th>\n",
       "      <th>unique_ports</th>\n",
       "      <th>has_suspicious_ports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.165205e+07</td>\n",
       "      <td>5376.344086</td>\n",
       "      <td>244.806452</td>\n",
       "      <td>13.709677</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.164915e+07</td>\n",
       "      <td>254.950272</td>\n",
       "      <td>15.640150</td>\n",
       "      <td>1.598781</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.506161e+06</td>\n",
       "      <td>5142.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.841450e+06</td>\n",
       "      <td>5284.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.921868e+06</td>\n",
       "      <td>5342.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.008240e+06</td>\n",
       "      <td>5394.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.865214e+08</td>\n",
       "      <td>6779.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bytes_sum  connection_count  unique_destinations  unique_ports  \\\n",
       "count  9.300000e+01         93.000000            93.000000     93.000000   \n",
       "mean   1.165205e+07       5376.344086           244.806452     13.709677   \n",
       "std    3.164915e+07        254.950272            15.640150      1.598781   \n",
       "min    5.506161e+06       5142.000000           160.000000      5.000000   \n",
       "25%    5.841450e+06       5284.000000           246.000000     14.000000   \n",
       "50%    5.921868e+06       5342.000000           248.000000     14.000000   \n",
       "75%    6.008240e+06       5394.000000           249.000000     14.000000   \n",
       "max    1.865214e+08       6779.000000           250.000000     14.000000   \n",
       "\n",
       "       has_suspicious_ports  \n",
       "count                  93.0  \n",
       "mean                    1.0  \n",
       "std                     0.0  \n",
       "min                     1.0  \n",
       "25%                     1.0  \n",
       "50%                     1.0  \n",
       "75%                     1.0  \n",
       "max                     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Applying Isolation Forest anomaly detection...\n",
      "\n",
      "üö® ANOMALOUS SOURCE IPs DETECTED: 10\n",
      "\n",
      "Top 5 most anomalous IPs:\n",
      "\n",
      "1. 91.234.99.12 (anomaly score: -0.314)\n",
      "   üìä Total bytes: 186,521,374\n",
      "   üîó Connections: 6779\n",
      "   üéØ Unique destinations: 160\n",
      "   üîå Unique ports: 5\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {1337: 1423, 9999: 1360, 8080: 1354, 4444: 1349, 31337: 1293}\n",
      "\n",
      "2. 185.220.70.43 (anomaly score: -0.279)\n",
      "   üìä Total bytes: 182,402,315\n",
      "   üîó Connections: 6670\n",
      "   üéØ Unique destinations: 160\n",
      "   üîå Unique ports: 5\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {4444: 1344, 31337: 1342, 1337: 1334, 8080: 1330, 9999: 1320}\n",
      "\n",
      "3. 194.233.164.24 (anomaly score: -0.273)\n",
      "   üìä Total bytes: 183,246,579\n",
      "   üîó Connections: 6665\n",
      "   üéØ Unique destinations: 160\n",
      "   üîå Unique ports: 5\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {31337: 1373, 4444: 1353, 8080: 1323, 1337: 1313, 9999: 1303}\n",
      "\n",
      "4. 192.168.1.98 (anomaly score: -0.067)\n",
      "   üìä Total bytes: 5,506,161\n",
      "   üîó Connections: 5236\n",
      "   üéØ Unique destinations: 246\n",
      "   üîå Unique ports: 14\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {143: 588, 25: 582, 53: 575, 995: 554, 110: 553}\n",
      "\n",
      "5. 192.168.1.24 (anomaly score: -0.039)\n",
      "   üìä Total bytes: 6,023,229\n",
      "   üîó Connections: 5233\n",
      "   üéØ Unique destinations: 248\n",
      "   üîå Unique ports: 14\n",
      "   ‚ö†Ô∏è  Has suspicious ports: Yes\n",
      "   üïê Session duration: 24.0 hours\n",
      "   üîå Top ports: {443: 581, 53: 578, 25: 548, 995: 542, 22: 541}\n",
      "\n",
      "‚è±Ô∏è ML analysis completed in 0.53 seconds\n"
     ]
    }
   ],
>>>>>>> main
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5afb9b7 (Cleared outputs)
   "source": [
    "# Time the ML analysis\n",
    "start_time = time.time()\n",
    "ml_results = ml_traffic_analysis(traffic_df)\n",
    "ml_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è ML analysis completed in {ml_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä METHOD COMPARISON - MODULE 1\n",
      "==================================================\n",
      "üéØ ACTUAL SUSPICIOUS IPs: ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
      "üîç BASIC METHOD found: ['91.234.99.12', '194.233.164.24', '185.220.70.43']\n",
      "ü§ñ ML METHOD found: ['91.234.99.12', '185.220.70.43', '194.233.164.24', '192.168.1.98', '192.168.1.24']...\n",
      "\n",
      "üìà DETECTION RESULTS:\n",
      "   Basic method detected: 3/3 suspicious IPs\n",
      "   ML method detected: 3/3 suspicious IPs\n",
      "\n",
      "‚è±Ô∏è TIMING COMPARISON:\n",
      "   Basic method: 0.38 seconds\n",
      "   ML method: 0.53 seconds\n",
      "   Speed difference: 1.4x slower. \n",
      "\n",
      "For basic analysis on relatively small datasets, \n",
      "the two methods have similar runtimes, but for larger datasets, ML methods may take longer. \n",
      "It can also take a while to fine-tune the features extracted and to work through any false positives!\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "‚úÖ Use BASIC METHOD when:\n",
      "   ‚Ä¢ You need results very quickly\n",
      "   ‚Ä¢ Looking for known bad indicators\n",
      "   ‚Ä¢ Working with smaller dataset\n",
      "   ‚Ä¢ Need explainable results for management\n",
      "\n",
      "‚úÖ Use ML METHOD when:\n",
      "   ‚Ä¢ Unknown threat patterns\n",
      "   ‚Ä¢ Large datasets\n",
      "   ‚Ä¢ Building automated detection\n",
      "   ‚Ä¢ Complex behavioral analysis needed\n"
     ]
    }
   ],
>>>>>>> main
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5afb9b7 (Cleared outputs)
   "source": [
    "def compare_methods_module1():\n",
    "    \"\"\"Compare the effectiveness of basic vs ML methods\"\"\"\n",
    "    \n",
    "    print(\"üìä METHOD COMPARISON - MODULE 1\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get the actual suspicious IPs from our data generation\n",
    "    actual_suspicious = ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
    "    \n",
    "    # Basic method results\n",
    "    basic_suspicious = basic_results['external_ips']['source_ip'].unique() if len(basic_results['external_ips']) > 0 else []\n",
    "    \n",
    "    # ML method results\n",
    "    ml_suspicious = ml_results['anomalies'].index.tolist()\n",
    "    \n",
    "    print(f\"üéØ ACTUAL SUSPICIOUS IPs: {actual_suspicious}\")\n",
    "    print(f\"üîç BASIC METHOD found: {list(basic_suspicious)}\")\n",
    "    print(f\"ü§ñ ML METHOD found: {ml_suspicious[:5]}...\")  # Show top 5\n",
    "    \n",
    "    # Calculate detection rates\n",
    "    basic_detected = len(set(basic_suspicious) & set(actual_suspicious))\n",
    "    ml_detected = len(set(ml_suspicious) & set(actual_suspicious))\n",
    "    \n",
    "    print(f\"\\nüìà DETECTION RESULTS:\")\n",
    "    print(f\"   Basic method detected: {basic_detected}/{len(actual_suspicious)} suspicious IPs\")\n",
    "    print(f\"   ML method detected: {ml_detected}/{len(actual_suspicious)} suspicious IPs\")\n",
    "    \n",
    "    # Show timing comparison\n",
    "    print(f\"\\n‚è±Ô∏è TIMING COMPARISON:\")\n",
    "    print(f\"   Basic method: {basic_time:.2f} seconds\")\n",
    "    print(f\"   ML method: {ml_time:.2f} seconds\")\n",
    "    print(f\"   Speed difference: {ml_time/basic_time:.1f}x slower. \\n\\nFor basic analysis on relatively small datasets, \\nthe two methods have similar runtimes, but for larger datasets, ML methods may take longer. \\nIt can also take a while to fine-tune the features extracted and to work through any false positives!\")\n",
    "    \n",
    "    # When to use each method\n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "    print(\"‚úÖ Use BASIC METHOD when:\")\n",
    "    print(\"   ‚Ä¢ You need results very quickly\")\n",
    "    print(\"   ‚Ä¢ Looking for known bad indicators\")\n",
    "    print(\"   ‚Ä¢ Need explainable results for management\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Use ML METHOD when:\")\n",
    "    print(\"   ‚Ä¢ Unknown threat patterns\")\n",
    "    print(\"   ‚Ä¢ Building automated detection\")\n",
    "    print(\"   ‚Ä¢ Complex behavioral analysis needed\")\n",
    "\n",
    "compare_methods_module1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# Lesson 2: The Incident Responder Under Pressure\n",
    "# **Persona**: IR team member with 30 minutes to determine if an alert is real\n",
    "# \n",
    "# **Scenario**: Authentication logs showing potential brute force attacks\n",
    "# \n",
    "# **Question**: Pivot tables or behavioral modeling?\n",
    "\n",
    "# 2.1 Import Authentication Dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 5afb9b7 (Cleared outputs)
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_df = pd.read_csv(f\"{DATA_DIR}/auth_logs.csv\")\n",
    "auth_df['timestamp'] = pd.to_datetime(auth_df['timestamp'])\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(auth_df.head())\n",
    "\n",
    "# Quick overview\n",
    "print(f\"\\nüìà Event breakdown:\")\n",
    "print(auth_df['event_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2.2 Basic Analysis (Excel-Style)\n",
    "# **‚è±Ô∏è Time Limit: 5 minutes**\n",
    "\n",
    "# %%\n",
    "def basic_auth_analysis(df):\n",
    "    \"\"\"Basic authentication analysis using simple aggregations\"\"\"\n",
    "    \n",
    "    print(\"üîé BASIC AUTH ANALYSIS (Excel-style)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analysis 1: Failed login attempts by source IP\n",
    "    failed_logins = df[df['event_type'] == 'login_failure']\n",
    "    \n",
    "    print(f\"\\nüìä FAILED LOGIN SUMMARY:\")\n",
    "    print(f\"Total failed logins: {len(failed_logins):,}\")\n",
    "    print(f\"Unique source IPs: {failed_logins['source_ip'].nunique()}\")\n",
    "    print(f\"Unique usernames targeted: {failed_logins['username'].nunique()}\")\n",
    "    \n",
    "    # Top IPs by failed attempts\n",
    "    ip_failures = failed_logins.groupby('source_ip').agg({\n",
    "        'username': ['count', 'nunique'],\n",
    "        'timestamp': ['min', 'max']\n",
    "    })\n",
    "    ip_failures.columns = ['total_failures', 'unique_users_targeted', 'first_attempt', 'last_attempt']\n",
    "    ip_failures['attack_duration_minutes'] = (\n",
    "        ip_failures['last_attempt'] - ip_failures['first_attempt']\n",
    "    ).dt.total_seconds() / 60\n",
    "    \n",
    "    ip_failures = ip_failures.sort_values('total_failures', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP 10 SOURCE IPs BY FAILED ATTEMPTS:\")\n",
    "    display(ip_failures.head(10))\n",
    "    \n",
    "    # Simple brute force detection (threshold-based)\n",
    "    brute_force_threshold = 20\n",
    "    potential_attackers = ip_failures[ip_failures['total_failures'] >= brute_force_threshold]\n",
    "    \n",
    "    print(f\"\\nüö® POTENTIAL BRUTE FORCE ATTACKERS (‚â•{brute_force_threshold} failures):\")\n",
    "    if len(potential_attackers) > 0:\n",
    "        for ip, row in potential_attackers.iterrows():\n",
    "            print(f\"\\nüìç {ip}:\")\n",
    "            print(f\"   üí• Total failures: {row['total_failures']}\")\n",
    "            print(f\"   üë§ Users targeted: {row['unique_users_targeted']}\")\n",
    "            print(f\"   ‚è±Ô∏è  Attack duration: {row['attack_duration_minutes']:.1f} minutes\")\n",
    "            \n",
    "            # Show most targeted usernames for this IP\n",
    "            ip_targets = failed_logins[failed_logins['source_ip'] == ip]['username'].value_counts().head(5)\n",
    "            print(f\"   üéØ Top targets: {dict(ip_targets)}\")\n",
    "    else:\n",
    "        print(\"No IPs exceed the brute force threshold\")\n",
    "    \n",
    "    # Time-based analysis\n",
    "    failed_logins['hour'] = failed_logins['timestamp'].dt.hour\n",
    "    hourly_failures = failed_logins.groupby('hour').size()\n",
    "    \n",
    "    print(f\"\\nüïê FAILED LOGINS BY HOUR:\")\n",
    "    peak_hour = hourly_failures.idxmax()\n",
    "    print(f\"Peak hour: {peak_hour}:00 with {hourly_failures[peak_hour]} failures\")\n",
    "    \n",
    "    return {\n",
    "        'ip_failures': ip_failures,\n",
    "        'potential_attackers': potential_attackers,\n",
    "        'hourly_failures': hourly_failures,\n",
    "        'failed_logins': failed_logins\n",
    "    }\n",
    "\n",
    "# Time the basic analysis\n",
    "start_time = time.time()\n",
    "basic_auth_results = basic_auth_analysis(auth_df)\n",
    "basic_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Basic analysis completed in {basic_auth_time:.2f} seconds\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.3 Machine Learning Analysis\n",
    "\n",
    "# %%\n",
    "def ml_auth_analysis(df):\n",
    "    \"\"\"ML-based authentication analysis using behavioral modeling\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ ML AUTHENTICATION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create time windows for behavioral analysis\n",
    "    print(\"\\nüîß Creating behavioral features with time windows...\")\n",
    "    \n",
    "    # Use 10-minute time windows\n",
    "    df['time_window'] = df['timestamp'].dt.floor('10min')\n",
    "    \n",
    "    # Create features per IP per time window\n",
    "    window_features = df.groupby(['source_ip', 'time_window']).agg({\n",
    "        'username': ['nunique', 'count'],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()],\n",
    "        'service': 'nunique'\n",
    "    })\n",
    "    \n",
    "    window_features.columns = ['unique_users', 'total_attempts', 'failures', 'successes', 'unique_services']\n",
    "    \n",
    "    # Calculate rates and ratios\n",
    "    window_features['failure_rate'] = window_features['failures'] / window_features['total_attempts']\n",
    "    window_features['attempts_per_minute'] = window_features['total_attempts'] / 10  # 10-minute windows\n",
    "    window_features['user_diversity'] = window_features['unique_users'] / window_features['total_attempts']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    window_features = window_features.fillna(0)\n",
    "    \n",
    "    # Add IP-level behavioral features\n",
    "    ip_features = df.groupby('source_ip').agg({\n",
    "        'username': 'nunique',\n",
    "        'timestamp': ['count', lambda x: (x.max() - x.min()).total_seconds() / 3600],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()]\n",
    "    })\n",
    "    \n",
    "    ip_features.columns = ['total_unique_users', 'total_attempts', 'session_duration_hours', \n",
    "                          'total_failures', 'total_successes']\n",
    "    ip_features['overall_failure_rate'] = ip_features['total_failures'] / ip_features['total_attempts']\n",
    "    \n",
    "    # Check if IP is external (simple heuristic)\n",
    "    ip_features['is_external'] = ~ip_features.index.str.startswith('192.168.')\n",
    "    ip_features['is_external'] = ip_features['is_external'].astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Created features for {len(window_features)} time windows across {len(ip_features)} IPs\")\n",
    "    \n",
    "    # Apply clustering to find unusual patterns in time windows\n",
    "    print(\"\\nüîç Applying DBSCAN clustering on time window features...\")\n",
    "    \n",
    "    # Select features for clustering\n",
    "    cluster_features = window_features[['unique_users', 'total_attempts', 'failure_rate', \n",
    "                                      'attempts_per_minute', 'user_diversity']].copy()\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(cluster_features)\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=4)\n",
    "    clusters = dbscan.fit_predict(features_scaled)\n",
    "    \n",
    "    # Add cluster labels\n",
    "    window_features['cluster'] = clusters\n",
    "    \n",
    "    # Analyze outliers (cluster -1)\n",
    "    outliers = window_features[window_features['cluster'] == -1]\n",
    "    \n",
    "    print(f\"\\nüö® ANOMALOUS TIME WINDOWS DETECTED: {len(outliers)}\")\n",
    "    \n",
    "    # Group outliers by IP for analysis\n",
    "    outlier_ips = outliers.groupby(level='source_ip').agg({\n",
    "        'total_attempts': ['sum', 'max'],\n",
    "        'failures': ['sum', 'max'],\n",
    "        'failure_rate': 'mean',\n",
    "        'attempts_per_minute': 'max',\n",
    "        'unique_users': 'max'\n",
    "    })\n",
    "    \n",
    "    outlier_ips.columns = ['total_attempts', 'max_attempts_per_window', 'total_failures', \n",
    "                          'max_failures_per_window', 'avg_failure_rate', \n",
    "                          'max_attempts_per_minute', 'max_users_per_window']\n",
    "    \n",
    "    # Sort by severity\n",
    "    outlier_ips['severity_score'] = (\n",
    "        outlier_ips['max_attempts_per_minute'] * 0.4 +\n",
    "        outlier_ips['avg_failure_rate'] * 0.3 +\n",
    "        outlier_ips['max_users_per_window'] * 0.3\n",
    "    )\n",
    "    \n",
    "    outlier_ips = outlier_ips.sort_values('severity_score', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP SUSPICIOUS IPs BY ML ANALYSIS:\")\n",
    "    \n",
    "    for i, (ip, row) in enumerate(outlier_ips.head().iterrows()):\n",
    "        print(f\"\\n{i+1}. {ip} (severity score: {row['severity_score']:.2f})\")\n",
    "        print(f\"   üí• Total attempts: {row['total_attempts']}\")\n",
    "        print(f\"   üìà Max attempts/minute: {row['max_attempts_per_minute']:.1f}\")\n",
    "        print(f\"   ‚ùå Average failure rate: {row['avg_failure_rate']:.2%}\")\n",
    "        print(f\"   üë• Max users targeted in one window: {row['max_users_per_window']}\")\n",
    "        \n",
    "        # Show timeline for this IP\n",
    "        ip_data = df[df['source_ip'] == ip]\n",
    "        print(f\"   üìÖ Active period: {ip_data['timestamp'].min()} to {ip_data['timestamp'].max()}\")\n",
    "        \n",
    "        # Show most common usernames\n",
    "        top_users = ip_data['username'].value_counts().head(3)\n",
    "        print(f\"   üéØ Top targets: {dict(top_users)}\")\n",
    "    \n",
    "    return {\n",
    "        'window_features': window_features,\n",
    "        'ip_features': ip_features,\n",
    "        'outliers': outliers,\n",
    "        'outlier_ips': outlier_ips,\n",
    "        'clusters': clusters\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the ML analysis\n",
    "start_time = time.time()\n",
    "ml_auth_results = ml_auth_analysis(auth_df)\n",
    "ml_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è ML analysis completed in {ml_auth_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods_module2():\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üî¨ **Deep Dive: Method Comparison Analysis**\n",
    "# \n",
    "# Let's create a detailed comparison of how well each method actually performed on our authentication data.\n",
    "\n",
    "# %%\n",
    "    def detailed_method_comparison():\n",
    "        \"\"\"Comprehensive comparison of Excel-style vs ML methods\"\"\"\n",
    "        \n",
    "        print(\"üî¨ DETAILED METHOD COMPARISON ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Get the actual suspicious IPs from our data generation\n",
    "        actual_attackers = ['203.0.113.15', '198.51.100.42', '192.0.2.123', '185.199.108.153']\n",
    "        \n",
    "        # Basic method results\n",
    "        basic_suspicious = basic_auth_results['potential_attackers'].index.tolist()\n",
    "        \n",
    "        # ML method results\n",
    "        ml_suspicious = ml_auth_results['outlier_ips'].index.tolist()\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_data = []\n",
    "        \n",
    "        # Analyze each actual attacker\n",
    "        for ip in actual_attackers:\n",
    "            basic_detected = ip in basic_suspicious\n",
    "            ml_detected = ip in ml_suspicious\n",
    "            \n",
    "            # Get actual behavior data\n",
    "            ip_data = auth_df[auth_df['source_ip'] == ip]\n",
    "            total_attempts = len(ip_data)\n",
    "            failures = len(ip_data[ip_data['event_type'] == 'login_failure'])\n",
    "            unique_users = ip_data['username'].nunique()\n",
    "            time_span = (ip_data['timestamp'].max() - ip_data['timestamp'].min()).total_seconds() / 60\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'ip': ip,\n",
    "                'actual_attacker': True,\n",
    "                'basic_detected': basic_detected,\n",
    "                'ml_detected': ml_detected,\n",
    "                'total_attempts': total_attempts,\n",
    "                'failures': failures,\n",
    "                'failure_rate': failures / total_attempts if total_attempts > 0 else 0,\n",
    "                'unique_users': unique_users,\n",
    "                'time_span_minutes': time_span\n",
    "            })\n",
    "        \n",
    "        # Analyze false positives\n",
    "        all_detected = set(basic_suspicious + ml_suspicious)\n",
    "        false_positives = all_detected - set(actual_attackers)\n",
    "        \n",
    "        for ip in false_positives:\n",
    "            basic_detected = ip in basic_suspicious\n",
    "            ml_detected = ip in ml_suspicious\n",
    "            \n",
    "            # Get behavior data\n",
    "            ip_data = auth_df[auth_df['source_ip'] == ip]\n",
    "            total_attempts = len(ip_data)\n",
    "            failures = len(ip_data[ip_data['event_type'] == 'login_failure'])\n",
    "            unique_users = ip_data['username'].nunique()\n",
    "            time_span = (ip_data['timestamp'].max() - ip_data['timestamp'].min()).total_seconds() / 60\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'ip': ip,\n",
    "                'actual_attacker': False,\n",
    "                'basic_detected': basic_detected,\n",
    "                'ml_detected': ml_detected,\n",
    "                'total_attempts': total_attempts,\n",
    "                'failures': failures,\n",
    "                'failure_rate': failures / total_attempts if total_attempts > 0 else 0,\n",
    "                'unique_users': unique_users,\n",
    "                'time_span_minutes': time_span\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        print(\"üìä DETECTION RESULTS SUMMARY:\")\n",
    "        print(comparison_df[['ip', 'actual_attacker', 'basic_detected', 'ml_detected', 'failures', 'unique_users']].to_string(index=False))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        actual_positives = comparison_df[comparison_df['actual_attacker'] == True]\n",
    "        \n",
    "        # True Positives\n",
    "        basic_tp = len(actual_positives[(actual_positives['basic_detected'] == True)])\n",
    "        ml_tp = len(actual_positives[(actual_positives['ml_detected'] == True)])\n",
    "        \n",
    "        # False Negatives  \n",
    "        basic_fn = len(actual_positives[(actual_positives['basic_detected'] == False)])\n",
    "        ml_fn = len(actual_positives[(actual_positives['ml_detected'] == False)])\n",
    "        \n",
    "        # False Positives\n",
    "        basic_fp = len(comparison_df[(comparison_df['actual_attacker'] == False) & (comparison_df['basic_detected'] == True)])\n",
    "        ml_fp = len(comparison_df[(comparison_df['actual_attacker'] == False) & (comparison_df['ml_detected'] == True)])\n",
    "        \n",
    "        # True Negatives (all other IPs that weren't flagged)\n",
    "        total_unique_ips = auth_df['source_ip'].nunique()\n",
    "        basic_tn = total_unique_ips - basic_tp - basic_fn - basic_fp\n",
    "        ml_tn = total_unique_ips - ml_tp - ml_fn - ml_fp\n",
    "        \n",
    "        print(f\"\\nüìà CONFUSION MATRIX ANALYSIS:\")\n",
    "        print(f\"Total unique IPs in dataset: {total_unique_ips}\")\n",
    "        print(f\"Actual attackers: {len(actual_attackers)}\")\n",
    "        \n",
    "        print(f\"\\nüîç BASIC METHOD:\")\n",
    "        print(f\"  ‚úÖ True Positives (attackers caught): {basic_tp}\")\n",
    "        print(f\"  ‚ùå False Negatives (attackers missed): {basic_fn}\")\n",
    "        print(f\"  ‚ö†Ô∏è  False Positives (innocent flagged): {basic_fp}\")\n",
    "        print(f\"  ‚úÖ True Negatives (innocent ignored): {basic_tn}\")\n",
    "        \n",
    "        print(f\"\\nü§ñ ML METHOD:\")\n",
    "        print(f\"  ‚úÖ True Positives (attackers caught): {ml_tp}\")\n",
    "        print(f\"  ‚ùå False Negatives (attackers missed): {ml_fn}\")\n",
    "        print(f\"  ‚ö†Ô∏è  False Positives (innocent flagged): {ml_fp}\")\n",
    "        print(f\"  ‚úÖ True Negatives (innocent ignored): {ml_tn}\")\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        def calculate_metrics(tp, fp, fn, tn):\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "            return precision, recall, f1, accuracy\n",
    "        \n",
    "        basic_precision, basic_recall, basic_f1, basic_accuracy = calculate_metrics(basic_tp, basic_fp, basic_fn, basic_tn)\n",
    "        ml_precision, ml_recall, ml_f1, ml_accuracy = calculate_metrics(ml_tp, ml_fp, ml_fn, ml_tn)\n",
    "        \n",
    "        print(f\"\\nüéØ PERFORMANCE METRICS:\")\n",
    "        \n",
    "        print(f\"\\nüìä BASIC METHOD SCORES:\")\n",
    "        print(f\"  Precision (when I say attacker, how often am I right?): {basic_precision:.2%}\")\n",
    "        print(f\"  Recall (what % of attackers did I catch?): {basic_recall:.2%}\")\n",
    "        print(f\"  F1-Score (balanced measure): {basic_f1:.3f}\")\n",
    "        print(f\"  Accuracy (overall correctness): {basic_accuracy:.2%}\")\n",
    "        \n",
    "        print(f\"\\nü§ñ ML METHOD SCORES:\")\n",
    "        print(f\"  Precision (when I say attacker, how often am I right?): {ml_precision:.2%}\")\n",
    "        print(f\"  Recall (what % of attackers did I catch?): {ml_recall:.2%}\")\n",
    "        print(f\"  F1-Score (balanced measure): {ml_f1:.3f}\")\n",
    "        print(f\"  Accuracy (overall correctness): {ml_accuracy:.2%}\")\n",
    "        \n",
    "        # Visual comparison\n",
    "        metrics_comparison = pd.DataFrame({\n",
    "            'Method': ['Basic (Excel-style)', 'ML (Behavioral)'],\n",
    "            'Precision': [basic_precision, ml_precision],\n",
    "            'Recall': [basic_recall, ml_recall],\n",
    "            'F1-Score': [basic_f1, ml_f1],\n",
    "            'Accuracy': [basic_accuracy, ml_accuracy]\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nüìä SIDE-BY-SIDE COMPARISON:\")\n",
    "        display(metrics_comparison.round(3))\n",
    "        \n",
    "        # Analyze WHY differences occurred\n",
    "        print(f\"\\nü§î WHY THE DIFFERENCES?\")\n",
    "        \n",
    "        # Look at false positives\n",
    "        if basic_fp > 0 or ml_fp > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  FALSE POSITIVE ANALYSIS:\")\n",
    "            false_pos_ips = comparison_df[comparison_df['actual_attacker'] == False]\n",
    "            \n",
    "            for _, row in false_pos_ips.iterrows():\n",
    "                if row['basic_detected'] or row['ml_detected']:\n",
    "                    print(f\"\\n  üìç {row['ip']} (probably legitimate user with issues):\")\n",
    "                    print(f\"    Basic method flagged: {'Yes' if row['basic_detected'] else 'No'}\")\n",
    "                    print(f\"    ML method flagged: {'Yes' if row['ml_detected'] else 'No'}\")\n",
    "                    print(f\"    Behavior: {row['failures']} failures, {row['unique_users']} users, {row['time_span_minutes']:.1f} min span\")\n",
    "                    \n",
    "                    # Explain why each method flagged it\n",
    "                    if row['basic_detected']:\n",
    "                        print(f\"    üîç Basic flagged because: {row['failures']} failures exceeded threshold\")\n",
    "                    if row['ml_detected']:\n",
    "                        print(f\"    ü§ñ ML flagged because: behavioral pattern differed from normal users\")\n",
    "        \n",
    "        # Look at missed attackers\n",
    "        missed_attackers = comparison_df[(comparison_df['actual_attacker'] == True) & \n",
    "                                    ((comparison_df['basic_detected'] == False) | \n",
    "                                        (comparison_df['ml_detected'] == False))]\n",
    "        \n",
    "        if len(missed_attackers) > 0:\n",
    "            print(f\"\\n‚ùå MISSED ATTACKER ANALYSIS:\")\n",
    "            for _, row in missed_attackers.iterrows():\n",
    "                print(f\"\\n  üö® {row['ip']} (actual attacker that was missed):\")\n",
    "                print(f\"    Basic method missed: {'Yes' if not row['basic_detected'] else 'No'}\")\n",
    "                print(f\"    ML method missed: {'Yes' if not row['ml_detected'] else 'No'}\")\n",
    "                print(f\"    Actual behavior: {row['failures']} failures, {row['unique_users']} users\")\n",
    "                \n",
    "                if not row['basic_detected']:\n",
    "                    print(f\"    üîç Basic missed because: {row['failures']} failures below threshold\")\n",
    "                if not row['ml_detected']:\n",
    "                    print(f\"    ü§ñ ML missed because: behavior appeared 'normal' in aggregate\")\n",
    "        \n",
    "        # Practical recommendations\n",
    "        print(f\"\\nüí° PRACTICAL RECOMMENDATIONS:\")\n",
    "        \n",
    "        if basic_precision > ml_precision:\n",
    "            print(f\"  ‚úÖ Basic method has higher precision - fewer false alarms for analysts\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ ML method has higher precision - fewer false alarms for analysts\")\n",
    "        \n",
    "        if basic_recall > ml_recall:\n",
    "            print(f\"  ‚úÖ Basic method has higher recall - catches more attackers\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ ML method has higher recall - catches more attackers\")\n",
    "        \n",
    "        print(f\"\\nüéØ FOR THIS DATASET, RECOMMEND:\")\n",
    "        \n",
    "        if basic_f1 > ml_f1:\n",
    "            print(f\"  üìä Use BASIC METHOD - better overall balance of precision/recall\")\n",
    "            print(f\"  üïê Faster results: {basic_auth_time:.1f}s vs {ml_auth_time:.1f}s\")\n",
    "            print(f\"  üë• Easier to explain to management and junior analysts\")\n",
    "        else:\n",
    "            print(f\"  ü§ñ Use ML METHOD - better overall balance of precision/recall\")\n",
    "            print(f\"  üîç Better at finding subtle attack patterns\")\n",
    "            print(f\"  üìà Scales better with larger datasets\")\n",
    "        \n",
    "        print(f\"\\nüîÑ HYBRID APPROACH SUGGESTION:\")\n",
    "        print(f\"  1. Use BASIC method for immediate triage (< 30 seconds)\")\n",
    "        print(f\"  2. Use ML method for deeper analysis of suspicious activity\")\n",
    "        print(f\"  3. Combine results: HIGH confidence if both methods agree\")\n",
    "        \n",
    "        return comparison_df, metrics_comparison\n",
    "\n",
    "    # Run the detailed comparison\n",
    "    comparison_results, metrics_df = detailed_method_comparison()\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## üìà **Visualization: Method Performance Comparison**\n",
    "\n",
    "    # %%\n",
    "    def visualize_method_comparison(metrics_df):\n",
    "        \"\"\"Create visualizations comparing the two methods\"\"\"\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Excel-style vs ML Method Comparison', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        methods = metrics_df['Method']\n",
    "        \n",
    "        # Precision comparison\n",
    "        ax1.bar(methods, metrics_df['Precision'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax1.set_title('Precision: When I say \"attacker\", how often am I right?')\n",
    "        ax1.set_ylabel('Precision Score')\n",
    "        ax1.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['Precision']):\n",
    "            ax1.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "        \n",
    "        # Recall comparison  \n",
    "        ax2.bar(methods, metrics_df['Recall'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax2.set_title('Recall: What % of attackers did I catch?')\n",
    "        ax2.set_ylabel('Recall Score')\n",
    "        ax2.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['Recall']):\n",
    "            ax2.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "        \n",
    "        # F1-Score comparison\n",
    "        ax3.bar(methods, metrics_df['F1-Score'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax3.set_title('F1-Score: Balanced measure of performance')\n",
    "        ax3.set_ylabel('F1-Score')\n",
    "        ax3.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['F1-Score']):\n",
    "            ax3.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "        \n",
    "        # Accuracy comparison\n",
    "        ax4.bar(methods, metrics_df['Accuracy'], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "        ax4.set_title('Accuracy: Overall correctness')\n",
    "        ax4.set_ylabel('Accuracy Score') \n",
    "        ax4.set_ylim(0, 1.2)\n",
    "        for i, v in enumerate(metrics_df['Accuracy']):\n",
    "            ax4.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create a radar chart for overall comparison\n",
    "        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))\n",
    "        \n",
    "        categories = ['Precision', 'Recall', 'F1-Score', 'Accuracy']\n",
    "        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Complete the circle\n",
    "        \n",
    "        # Basic method\n",
    "        basic_values = metrics_df.iloc[0][1:].tolist()\n",
    "        basic_values += basic_values[:1]\n",
    "        ax.plot(angles, basic_values, 'o-', linewidth=2, label='Excel-style (Basic)', color='#3498db')\n",
    "        ax.fill(angles, basic_values, alpha=0.25, color='#3498db')\n",
    "        \n",
    "        # ML method  \n",
    "        ml_values = metrics_df.iloc[1][1:].tolist()\n",
    "        ml_values += ml_values[:1]\n",
    "        ax.plot(angles, ml_values, 'o-', linewidth=2, label='ML (Behavioral)', color='#e74c3c')\n",
    "        ax.fill(angles, ml_values, alpha=0.25, color='#e74c3c')\n",
    "        \n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(categories)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_title('Overall Method Performance Comparison\\n(Larger area = Better performance)', \n",
    "                    pad=20, fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "        ax.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Create the visualizations\n",
    "    visualize_method_comparison(metrics_df)\n",
    "\n",
    "    # %% [markdown]\n",
    "    # ## üéì **Key Takeaways: When to Use Each Method**\n",
    "\n",
    "    # %%\n",
    "    def print_decision_guide():\n",
    "        \"\"\"Print a practical guide for choosing between methods\"\"\"\n",
    "        \n",
    "        print(\"üéì DECISION GUIDE: EXCEL vs ML FOR AUTHENTICATION ANALYSIS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(\"\\nüîç USE EXCEL/BASIC METHOD WHEN:\")\n",
    "        print(\"  ‚úÖ You need results RIGHT NOW (active incident)\")\n",
    "        print(\"  ‚úÖ Your team is not comfortable with Python/ML\")\n",
    "        print(\"  ‚úÖ You have clear, simple thresholds (>50 failed logins = investigate)\")\n",
    "        print(\"  ‚úÖ Dataset is small (<10K authentication events)\")\n",
    "        print(\"  ‚úÖ Attackers are 'noisy' (many failed attempts)\")\n",
    "        print(\"  ‚úÖ You need to explain results to management\")\n",
    "        \n",
    "        print(f\"  ‚è±Ô∏è  Time to results: {basic_auth_time:.1f} seconds\")\n",
    "        print(f\"  üéØ Best for: Incident response, SOC triage, management reporting\")\n",
    "        \n",
    "        print(\"\\nü§ñ USE ML/BEHAVIORAL METHOD WHEN:\")\n",
    "        print(\"  ‚úÖ You have time for deeper analysis (threat hunting)\")\n",
    "        print(\"  ‚úÖ Your team has ML/Python skills\")\n",
    "        print(\"  ‚úÖ Attackers might be sophisticated (low-and-slow attacks)\")\n",
    "        print(\"  ‚úÖ Dataset is large (>10K authentication events)\")\n",
    "        print(\"  ‚úÖ You want to find subtle patterns\")\n",
    "        print(\"  ‚úÖ You're building automated detection systems\")\n",
    "        \n",
    "        print(f\"  ‚è±Ô∏è  Time to results: {ml_auth_time:.1f} seconds\")\n",
    "        print(f\"  üéØ Best for: Threat hunting, advanced persistent threats, automation\")\n",
    "        \n",
    "        print(\"\\nüîÑ HYBRID APPROACH (RECOMMENDED):\")\n",
    "        print(\"  1Ô∏è‚É£  Start with BASIC method for quick wins\")\n",
    "        print(\"  2Ô∏è‚É£  Use ML method to double-check and find subtle threats\")\n",
    "        print(\"  3Ô∏è‚É£  Investigate anything flagged by BOTH methods first\")\n",
    "        print(\"  4Ô∏è‚É£  Use ML findings to improve your basic thresholds\")\n",
    "        \n",
    "        print(\"\\nüìä REAL-WORLD WORKFLOW:\")\n",
    "        print(\"  üö® Incident Response (0-30 min): Basic method only\")\n",
    "        print(\"  üîç Daily Threat Hunting (30+ min): ML method\")\n",
    "        print(\"  üìà Weekly Reviews: Compare both methods' findings\")\n",
    "        print(\"  üéØ Tuning: Use ML insights to improve basic rules\")\n",
    "        \n",
    "        print(\"\\n‚ö†Ô∏è  REMEMBER:\")\n",
    "        print(\"  ‚Ä¢ No method is perfect - always validate findings\")\n",
    "        print(\"  ‚Ä¢ Context matters more than algorithms\")\n",
    "        print(\"  ‚Ä¢ The best method is the one your team will actually use\")\n",
    "        print(\"  ‚Ä¢ Simple methods that work beat complex methods that don't\")\n",
    "\n",
    "def print_decision_guide():\n",
    "    \"\"\"Compare basic vs ML methods for authentication analysis\"\"\"\n",
    "        \n",
    "    print(\"üìä METHOD COMPARISON - MODULE 2\")\n",
    "    print(\"=\" * 50)\n",
    "        \n",
    "    # Known attack sources from our data generation\n",
    "    actual_attackers = ['203.0.113.15', '198.51.100.42', '192.0.2.123', '185.199.108.153']\n",
    "        \n",
    "    # Basic method results\n",
    "    basic_attackers = basic_auth_results['potential_attackers'].index.tolist()\n",
    "        \n",
    "    # ML method results  \n",
    "    ml_attackers = ml_auth_results['outlier_ips'].index.tolist()\n",
    "        \n",
    "    print(f\"üéØ ACTUAL ATTACK IPs: {actual_attackers}\")\n",
    "    print(f\"üîç BASIC METHOD found: {basic_attackers}\")\n",
    "    print(f\"ü§ñ ML METHOD found: {ml_attackers}\")\n",
    "        \n",
    "    # Calculate detection accuracy\n",
    "    basic_detected = len(set(basic_attackers) & set(actual_attackers))\n",
    "    ml_detected = len(set(ml_attackers) & set(actual_attackers))\n",
    "        \n",
    "    basic_false_positives = len(set(basic_attackers) - set(actual_attackers))\n",
    "    ml_false_positives = len(set(ml_attackers) - set(actual_attackers))\n",
    "        \n",
    "    print(f\"\\nüìà DETECTION RESULTS:\")\n",
    "    print(f\"   Basic method: {basic_detected}/{len(actual_attackers)} correct ({basic_detected/len(actual_attackers)*100:.0f}%)\")\n",
    "    print(f\"   ML method: {ml_detected}/{len(actual_attackers)} correct ({ml_detected/len(actual_attackers)*100:.0f}%)\")\n",
    "        \n",
    "    print(f\"\\n‚ùå FALSE POSITIVES:\")\n",
    "    print(f\"   Basic method: {basic_false_positives} false alarms\")\n",
    "    print(f\"   ML method: {ml_false_positives} false alarms\")\n",
    "        \n",
    "    print(f\"\\n‚è±Ô∏è TIMING COMPARISON:\")\n",
    "    print(f\"   Basic method: {basic_auth_time:.2f} seconds\")\n",
    "    print(f\"   ML method: {ml_auth_time:.2f} seconds\")\n",
    "    print(f\"   Speed difference: {ml_auth_time/basic_auth_time:.1f}x slower\")\n",
    "        \n",
    "    # Detailed analysis\n",
    "    print(f\"\\nüîç DETAILED ANALYSIS:\")\n",
    "        \n",
    "    if basic_false_positives > 0:\n",
    "        false_basic = set(basic_attackers) - set(actual_attackers)\n",
    "        print(f\"   Basic false positives: {list(false_basic)}\")\n",
    "        for fp_ip in false_basic:\n",
    "            fp_data = auth_df[auth_df['source_ip'] == fp_ip]\n",
    "            failures = len(fp_data[fp_data['event_type'] == 'login_failure'])\n",
    "            print(f\"     {fp_ip}: {failures} failed logins (legitimate user with password issues?)\")\n",
    "        \n",
    "    if ml_false_positives > 0:\n",
    "        false_ml = set(ml_attackers) - set(actual_attackers)\n",
    "        print(f\"   ML false positives: {list(false_ml)}\")\n",
    "        \n",
    "    print(f\"\\nüí° KEY INSIGHTS:\")\n",
    "    print(\"‚úÖ Basic method strengths:\")\n",
    "    print(\"   ‚Ä¢ Fast results for known attack patterns\")\n",
    "    print(\"   ‚Ä¢ Easy to explain to stakeholders\")\n",
    "    print(\"   ‚Ä¢ Good for simple threshold-based detection\")\n",
    "        \n",
    "    print(\"\\n‚úÖ ML method strengths:\")\n",
    "    print(\"   ‚Ä¢ Detects subtle behavioral anomalies\")\n",
    "    print(\"   ‚Ä¢ Better at finding sophisticated attacks\")\n",
    "    print(\"   ‚Ä¢ Can adapt to new attack patterns\")\n",
    "        \n",
    "    print(\"\\nüö® INCIDENT RESPONSE RECOMMENDATION:\")\n",
    "    if basic_detected == len(actual_attackers) and basic_false_positives == 0:\n",
    "        print(\"   Use BASIC method: Perfect detection with fast results!\")\n",
    "    elif ml_detected > basic_detected:\n",
    "        print(\"   Use ML method: Better detection of sophisticated attacks\")\n",
    "    else:\n",
    "        print(\"   Use HYBRID approach: Basic for triage, ML for deep analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_methods_module2()\n",
    "print_decision_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code used to generate the datasets used in these modules may be found below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_traffic_data(num_records=10000):\n",
    "    \"\"\"Generate realistic network traffic data with hidden anomalies\"\"\"\n",
    "    \n",
    "    # Normal traffic patterns\n",
    "    normal_sources = [f\"192.168.1.{i}\" for i in range(10, 100)]\n",
    "    normal_destinations = [f\"10.0.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    common_ports = [80, 443, 22, 25, 53, 110, 143, 993, 995]\n",
    "    \n",
    "    # Generate timestamps over last 24 hours\n",
    "    start_time = dt.now() - timedelta(hours=24)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Normal traffic (90% of data)\n",
    "    for _ in range(int(num_records * 0.90)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        source = random.choice(normal_sources)\n",
    "        destination = random.choice(normal_destinations)\n",
    "        port = random.choice(common_ports)\n",
    "        bytes_sent = random.randint(64, 1500)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    # Suspicious traffic (10% of data) - More obvious for Excel detection\n",
    "    suspicious_ips = ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
    "    suspicious_ports = [1337, 4444, 8080, 9999, 31337]\n",
    "    \n",
    "    for _ in range(int(num_records * 0.10)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        \n",
    "        if random.random() < 0.4:  # External suspicious IP\n",
    "            source = random.choice(suspicious_ips)\n",
    "            destination = random.choice(normal_destinations)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(5000, 50000)  # Much larger transfers\n",
    "        else:  # Internal lateral movement\n",
    "            source = random.choice(normal_sources)\n",
    "            destination = random.choice(normal_sources)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(2000, 10000)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.sample(frac=1).reset_index(drop=True)  # Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "traffic_df = generate_network_traffic_data(500000)\n",
    "print(f\"üìä Generated {len(traffic_df):,} network traffic records\")\n",
    "print(f\"üìÖ Time range: {traffic_df['timestamp'].min()} to {traffic_df['timestamp'].max()}\")\n",
    "\n",
    "# Save to CSV for Excel analysis\n",
    "traffic_df.to_csv(f\"{DATA_DIR}/network_traffic.csv\", index=False)\n",
    "print(\"üíæ Saved to network_traffic.csv\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(traffic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "execution_count": 53,
>>>>>>> main
=======
>>>>>>> 5afb9b7 (Cleared outputs)
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auth_logs(num_records=10000):\n",
    "    \"\"\"Generate authentication logs with brute force attacks\"\"\"\n",
    "    \n",
    "    # Normal users\n",
    "    normal_users = [f\"user{i:03d}\" for i in range(1, 201)]\n",
    "    normal_sources = [f\"192.168.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    \n",
    "    # Attackers\n",
    "    attack_sources = ['203.0.113.15', '198.51.100.42', '192.0.2.123']\n",
    "    attack_targets = ['admin', 'administrator', 'root', 'service', 'guest']\n",
    "    \n",
    "    data = []\n",
    "    start_time = dt.now() - timedelta(hours=6)\n",
    "    \n",
    "    # Normal successful logins (80%)\n",
    "    for _ in range(int(num_records * 0.8)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 21600))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_success',\n",
    "            'service': 'ssh'\n",
    "        })\n",
    "    \n",
    "    # Normal failed logins (15%)\n",
    "    for _ in range(int(num_records * 0.15)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 21600))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp,\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_failure',\n",
    "            'service': 'ssh'\n",
    "        })\n",
    "    \n",
    "    # Brute force attacks (5%)\n",
    "    for attacker_ip in attack_sources:\n",
    "        attack_start = start_time + timedelta(hours=random.randint(1, 4))\n",
    "        \n",
    "        # Generate rapid-fire attempts\n",
    "        for i in range(random.randint(50, 200)):\n",
    "            timestamp = attack_start + timedelta(seconds=i * random.randint(1, 5))\n",
    "            user = random.choice(attack_targets + normal_users[:20])\n",
    "            \n",
    "            data.append({\n",
    "                'timestamp': timestamp,\n",
    "                'username': user,\n",
    "                'source_ip': attacker_ip,\n",
    "                'event_type': 'login_failure',\n",
    "                'service': 'ssh'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def basic_auth_analysis(df):\n",
    "    \"\"\"Basic authentication analysis\"\"\"\n",
    "    \n",
    "    print(\"=== BASIC AUTH ANALYSIS ===\")\n",
    "    \n",
    "    # Failed login attempts by IP\n",
    "    failed_logins = df[df['event_type'] == 'login_failure']\n",
    "    ip_failures = failed_logins.groupby('source_ip').size().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nTop IPs by failed login attempts:\")\n",
    "    print(ip_failures.head(10))\n",
    "    \n",
    "    # Brute force detection (simple threshold)\n",
    "    brute_force_threshold = 20\n",
    "    potential_attackers = ip_failures[ip_failures >= brute_force_threshold]\n",
    "    \n",
    "    print(f\"\\nPotential brute force attackers (>={brute_force_threshold} failures):\")\n",
    "    for ip, count in potential_attackers.items():\n",
    "        ip_data = failed_logins[failed_logins['source_ip'] == ip]\n",
    "        unique_users = ip_data['username'].nunique()\n",
    "        time_span = (ip_data['timestamp'].max() - ip_data['timestamp'].min()).total_seconds() / 60\n",
    "        print(f\"  {ip}: {count} failures, {unique_users} users, {time_span:.1f} minutes\")\n",
    "    \n",
    "    return potential_attackers\n",
    "\n",
    "def ml_auth_analysis(df):\n",
    "    \"\"\"ML-based authentication analysis\"\"\"\n",
    "    \n",
    "    print(\"\\n=== ML AUTH ANALYSIS ===\")\n",
    "    \n",
    "    # Create time-based features\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    \n",
    "    # Aggregate by IP and time window (5-minute windows)\n",
    "    df['time_window'] = df['timestamp'].dt.floor('5min')\n",
    "    \n",
    "    features = df.groupby(['source_ip', 'time_window']).agg({\n",
    "        'username': 'nunique',\n",
    "        'event_type': lambda x: (x == 'login_failure').sum(),\n",
    "        'timestamp': 'count'\n",
    "    }).rename(columns={\n",
    "        'username': 'unique_users',\n",
    "        'event_type': 'failures',\n",
    "        'timestamp': 'total_attempts'\n",
    "    })\n",
    "    \n",
    "    # Calculate failure rate\n",
    "    features['failure_rate'] = features['failures'] / features['total_attempts']\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    # Apply clustering to find unusual patterns\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Use DBSCAN to find clusters\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    clusters = dbscan.fit_predict(features_scaled)\n",
    "    \n",
    "    # Analyze outliers (cluster -1)\n",
    "    outliers = features[clusters == -1]\n",
    "    \n",
    "    print(f\"\\nOutlier authentication patterns detected: {len(outliers)}\")\n",
    "    \n",
    "    # Group outliers by IP\n",
    "    for ip in outliers.index.get_level_values('source_ip').unique()[:5]:\n",
    "        ip_outliers = outliers[outliers.index.get_level_values('source_ip') == ip]\n",
    "        print(f\"\\n{ip}:\")\n",
    "        print(f\"  Outlier time windows: {len(ip_outliers)}\")\n",
    "        print(f\"  Max failures in 5min: {ip_outliers['failures'].max()}\")\n",
    "        print(f\"  Max unique users in 5min: {ip_outliers['unique_users'].max()}\")\n",
    "        print(f\"  Max failure rate: {ip_outliers['failure_rate'].max():.2f}\")\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_df = generate_auth_logs(10000)\n",
=======
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auth_logs(num_records=8000):\n",
    "    \"\"\"Generate authentication logs with brute force attacks\"\"\"\n",
    "    \n",
    "    # Normal users and systems\n",
    "    normal_users = [f\"user{i:03d}\" for i in range(1, 150)]\n",
    "    service_accounts = ['backup_svc', 'monitoring_svc', 'db_service', 'web_service']\n",
    "    normal_sources = [f\"192.168.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    \n",
    "    # Attack sources and targets\n",
    "    attack_sources = ['203.0.113.15', '198.51.100.42', '192.0.2.123', '185.199.108.153']\n",
    "    common_targets = ['admin', 'administrator', 'root', 'guest', 'test', 'user']\n",
    "    \n",
    "    data = []\n",
    "    start_time = dt.now() - timedelta(hours=8)\n",
    "    \n",
    "    # Normal successful logins (70%)\n",
    "    for _ in range(int(num_records * 0.70)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 28800))\n",
    "        user = random.choice(normal_users + service_accounts)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_success',\n",
    "            'service': random.choice(['ssh', 'rdp', 'web'])\n",
    "        })\n",
    "    \n",
    "    # Normal failed logins (20% - typos, expired passwords, etc.)\n",
    "    for _ in range(int(num_records * 0.20)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 28800))\n",
    "        user = random.choice(normal_users)\n",
    "        source = random.choice(normal_sources)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'username': user,\n",
    "            'source_ip': source,\n",
    "            'event_type': 'login_failure',\n",
    "            'service': random.choice(['ssh', 'rdp', 'web'])\n",
    "        })\n",
    "    \n",
    "    # Brute force attacks (10%)\n",
    "    for attacker_ip in attack_sources:\n",
    "        # Each attacker targets multiple accounts\n",
    "        attack_start = start_time + timedelta(hours=random.randint(1, 6))\n",
    "        \n",
    "        # Generate rapid-fire attempts\n",
    "        for i in range(random.randint(30, 120)):\n",
    "            timestamp = attack_start + timedelta(seconds=i * random.randint(1, 10))\n",
    "            \n",
    "            # Mix of common targets and real usernames\n",
    "            if random.random() < 0.6:\n",
    "                user = random.choice(common_targets)\n",
    "            else:\n",
    "                user = random.choice(normal_users[:30])  # Target real users too\n",
    "            \n",
    "            data.append({\n",
    "                'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'username': user,\n",
    "                'source_ip': attacker_ip,\n",
    "                'event_type': 'login_failure',\n",
    "                'service': 'ssh'\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.sort_values('timestamp').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Generated 3,883 authentication records\n",
      "üìÖ Time range: 2025-08-07 05:35:49 to 2025-08-07 13:35:23\n",
      "üíæ Saved to auth_logs.csv\n",
      "\n",
      "üîç Sample of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>username</th>\n",
       "      <th>source_ip</th>\n",
       "      <th>event_type</th>\n",
       "      <th>service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-07 05:35:49</td>\n",
       "      <td>user056</td>\n",
       "      <td>192.168.1.16</td>\n",
       "      <td>login_success</td>\n",
       "      <td>web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-07 05:35:57</td>\n",
       "      <td>user117</td>\n",
       "      <td>192.168.1.10</td>\n",
       "      <td>login_success</td>\n",
       "      <td>web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-07 05:35:59</td>\n",
       "      <td>user104</td>\n",
       "      <td>192.168.2.15</td>\n",
       "      <td>login_success</td>\n",
       "      <td>web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-07 05:36:11</td>\n",
       "      <td>user041</td>\n",
       "      <td>192.168.3.27</td>\n",
       "      <td>login_success</td>\n",
       "      <td>ssh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-07 05:36:13</td>\n",
       "      <td>user092</td>\n",
       "      <td>192.168.1.36</td>\n",
       "      <td>login_success</td>\n",
       "      <td>web</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp username     source_ip     event_type service\n",
       "0 2025-08-07 05:35:49  user056  192.168.1.16  login_success     web\n",
       "1 2025-08-07 05:35:57  user117  192.168.1.10  login_success     web\n",
       "2 2025-08-07 05:35:59  user104  192.168.2.15  login_success     web\n",
       "3 2025-08-07 05:36:11  user041  192.168.3.27  login_success     ssh\n",
       "4 2025-08-07 05:36:13  user092  192.168.1.36  login_success     web"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Event breakdown:\n",
      "event_type\n",
      "login_success    2800\n",
      "login_failure    1083\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 5afb9b7 (Cleared outputs)
   "source": [
    "auth_df = generate_auth_logs(4000)\n",
>>>>>>> main
    "print(f\"üìä Generated {len(auth_df):,} authentication records\")\n",
    "print(f\"üìÖ Time range: {auth_df['timestamp'].min()} to {auth_df['timestamp'].max()}\")\n",
    "\n",
    "# Save to CSV\n",
    "auth_df.to_csv('auth_logs.csv', index=False)\n",
    "print(\"üíæ Saved to auth_logs.csv\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(auth_df.head())\n",
    "\n",
    "# Quick overview\n",
    "print(f\"\\nüìà Event breakdown:\")\n",
    "print(auth_df['event_type'].value_counts())\n"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé BASIC AUTH ANALYSIS (Excel-style)\n",
      "==================================================\n",
      "\n",
      "üìä FAILED LOGIN SUMMARY:\n",
      "Total failed logins: 1,083\n",
      "Unique source IPs: 164\n",
      "Unique usernames targeted: 155\n",
      "\n",
      "üéØ TOP 10 SOURCE IPs BY FAILED ATTEMPTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_failures</th>\n",
       "      <th>unique_users_targeted</th>\n",
       "      <th>first_attempt</th>\n",
       "      <th>last_attempt</th>\n",
       "      <th>attack_duration_minutes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_ip</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203.0.113.15</th>\n",
       "      <td>98</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-08-07 09:35:24</td>\n",
       "      <td>2025-08-07 09:51:34</td>\n",
       "      <td>16.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198.51.100.42</th>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>2025-08-07 09:35:24</td>\n",
       "      <td>2025-08-07 09:45:54</td>\n",
       "      <td>10.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192.0.2.123</th>\n",
       "      <td>61</td>\n",
       "      <td>25</td>\n",
       "      <td>2025-08-07 11:35:24</td>\n",
       "      <td>2025-08-07 11:44:44</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185.199.108.153</th>\n",
       "      <td>58</td>\n",
       "      <td>21</td>\n",
       "      <td>2025-08-07 11:35:24</td>\n",
       "      <td>2025-08-07 11:44:14</td>\n",
       "      <td>8.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192.168.2.43</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-08-07 05:56:52</td>\n",
       "      <td>2025-08-07 12:58:08</td>\n",
       "      <td>421.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192.168.2.30</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-08-07 06:00:07</td>\n",
       "      <td>2025-08-07 13:02:43</td>\n",
       "      <td>422.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192.168.3.30</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2025-08-07 07:04:48</td>\n",
       "      <td>2025-08-07 12:19:13</td>\n",
       "      <td>314.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192.168.2.37</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-08-07 07:33:44</td>\n",
       "      <td>2025-08-07 12:16:49</td>\n",
       "      <td>283.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192.168.1.22</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-08-07 07:29:11</td>\n",
       "      <td>2025-08-07 13:20:50</td>\n",
       "      <td>351.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192.168.2.17</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-08-07 05:42:22</td>\n",
       "      <td>2025-08-07 13:35:04</td>\n",
       "      <td>472.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total_failures  unique_users_targeted       first_attempt  \\\n",
       "source_ip                                                                    \n",
       "203.0.113.15                 98                     31 2025-08-07 09:35:24   \n",
       "198.51.100.42                66                     23 2025-08-07 09:35:24   \n",
       "192.0.2.123                  61                     25 2025-08-07 11:35:24   \n",
       "185.199.108.153              58                     21 2025-08-07 11:35:24   \n",
       "192.168.2.43                 11                      9 2025-08-07 05:56:52   \n",
       "192.168.2.30                 11                     11 2025-08-07 06:00:07   \n",
       "192.168.3.30                 11                     11 2025-08-07 07:04:48   \n",
       "192.168.2.37                 10                     10 2025-08-07 07:33:44   \n",
       "192.168.1.22                 10                      9 2025-08-07 07:29:11   \n",
       "192.168.2.17                 10                     10 2025-08-07 05:42:22   \n",
       "\n",
       "                       last_attempt  attack_duration_minutes  \n",
       "source_ip                                                     \n",
       "203.0.113.15    2025-08-07 09:51:34                16.166667  \n",
       "198.51.100.42   2025-08-07 09:45:54                10.500000  \n",
       "192.0.2.123     2025-08-07 11:44:44                 9.333333  \n",
       "185.199.108.153 2025-08-07 11:44:14                 8.833333  \n",
       "192.168.2.43    2025-08-07 12:58:08               421.266667  \n",
       "192.168.2.30    2025-08-07 13:02:43               422.600000  \n",
       "192.168.3.30    2025-08-07 12:19:13               314.416667  \n",
       "192.168.2.37    2025-08-07 12:16:49               283.083333  \n",
       "192.168.1.22    2025-08-07 13:20:50               351.650000  \n",
       "192.168.2.17    2025-08-07 13:35:04               472.700000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö® POTENTIAL BRUTE FORCE ATTACKERS (‚â•20 failures):\n",
      "\n",
      "üìç 203.0.113.15:\n",
      "   üí• Total failures: 98\n",
      "   üë§ Users targeted: 31\n",
      "   ‚è±Ô∏è  Attack duration: 16.2 minutes\n",
      "   üéØ Top targets: {'admin': np.int64(11), 'root': np.int64(11), 'user': np.int64(9), 'administrator': np.int64(9), 'guest': np.int64(8)}\n",
      "\n",
      "üìç 198.51.100.42:\n",
      "   üí• Total failures: 66\n",
      "   üë§ Users targeted: 23\n",
      "   ‚è±Ô∏è  Attack duration: 10.5 minutes\n",
      "   üéØ Top targets: {'guest': np.int64(9), 'root': np.int64(8), 'administrator': np.int64(8), 'test': np.int64(5), 'admin': np.int64(5)}\n",
      "\n",
      "üìç 192.0.2.123:\n",
      "   üí• Total failures: 61\n",
      "   üë§ Users targeted: 25\n",
      "   ‚è±Ô∏è  Attack duration: 9.3 minutes\n",
      "   üéØ Top targets: {'guest': np.int64(11), 'root': np.int64(9), 'test': np.int64(5), 'administrator': np.int64(5), 'user': np.int64(4)}\n",
      "\n",
      "üìç 185.199.108.153:\n",
      "   üí• Total failures: 58\n",
      "   üë§ Users targeted: 21\n",
      "   ‚è±Ô∏è  Attack duration: 8.8 minutes\n",
      "   üéØ Top targets: {'admin': np.int64(10), 'administrator': np.int64(8), 'user': np.int64(7), 'root': np.int64(6), 'guest': np.int64(6)}\n",
      "\n",
      "üïê FAILED LOGINS BY HOUR:\n",
      "Peak hour: 9:00 with 263 failures\n",
      "\n",
      "‚è±Ô∏è Basic analysis completed in 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "# ## 2.2 Basic Analysis (Excel-Style)\n",
    "# **‚è±Ô∏è Time Limit: 5 minutes**\n",
    "\n",
    "# %%\n",
    "def basic_auth_analysis(df):\n",
    "    \"\"\"Basic authentication analysis using simple aggregations\"\"\"\n",
    "    \n",
    "    print(\"üîé BASIC AUTH ANALYSIS (Excel-style)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analysis 1: Failed login attempts by source IP\n",
    "    failed_logins = df[df['event_type'] == 'login_failure']\n",
    "    \n",
    "    print(f\"\\nüìä FAILED LOGIN SUMMARY:\")\n",
    "    print(f\"Total failed logins: {len(failed_logins):,}\")\n",
    "    print(f\"Unique source IPs: {failed_logins['source_ip'].nunique()}\")\n",
    "    print(f\"Unique usernames targeted: {failed_logins['username'].nunique()}\")\n",
    "    \n",
    "    # Top IPs by failed attempts\n",
    "    ip_failures = failed_logins.groupby('source_ip').agg({\n",
    "        'username': ['count', 'nunique'],\n",
    "        'timestamp': ['min', 'max']\n",
    "    })\n",
    "    ip_failures.columns = ['total_failures', 'unique_users_targeted', 'first_attempt', 'last_attempt']\n",
    "    ip_failures['attack_duration_minutes'] = (\n",
    "        ip_failures['last_attempt'] - ip_failures['first_attempt']\n",
    "    ).dt.total_seconds() / 60\n",
    "    \n",
    "    ip_failures = ip_failures.sort_values('total_failures', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP 10 SOURCE IPs BY FAILED ATTEMPTS:\")\n",
    "    display(ip_failures.head(10))\n",
    "    \n",
    "    # Simple brute force detection (threshold-based)\n",
    "    brute_force_threshold = 20\n",
    "    potential_attackers = ip_failures[ip_failures['total_failures'] >= brute_force_threshold]\n",
    "    \n",
    "    print(f\"\\nüö® POTENTIAL BRUTE FORCE ATTACKERS (‚â•{brute_force_threshold} failures):\")\n",
    "    if len(potential_attackers) > 0:\n",
    "        for ip, row in potential_attackers.iterrows():\n",
    "            print(f\"\\nüìç {ip}:\")\n",
    "            print(f\"   üí• Total failures: {row['total_failures']}\")\n",
    "            print(f\"   üë§ Users targeted: {row['unique_users_targeted']}\")\n",
    "            print(f\"   ‚è±Ô∏è  Attack duration: {row['attack_duration_minutes']:.1f} minutes\")\n",
    "            \n",
    "            # Show most targeted usernames for this IP\n",
    "            ip_targets = failed_logins[failed_logins['source_ip'] == ip]['username'].value_counts().head(5)\n",
    "            print(f\"   üéØ Top targets: {dict(ip_targets)}\")\n",
    "    else:\n",
    "        print(\"No IPs exceed the brute force threshold\")\n",
    "    \n",
    "    # Time-based analysis\n",
    "    failed_logins['hour'] = failed_logins['timestamp'].dt.hour\n",
    "    hourly_failures = failed_logins.groupby('hour').size()\n",
    "    \n",
    "    print(f\"\\nüïê FAILED LOGINS BY HOUR:\")\n",
    "    peak_hour = hourly_failures.idxmax()\n",
    "    print(f\"Peak hour: {peak_hour}:00 with {hourly_failures[peak_hour]} failures\")\n",
    "    \n",
    "    return {\n",
    "        'ip_failures': ip_failures,\n",
    "        'potential_attackers': potential_attackers,\n",
    "        'hourly_failures': hourly_failures,\n",
    "        'failed_logins': failed_logins\n",
    "    }\n",
    "\n",
    "# Time the basic analysis\n",
    "start_time = time.time()\n",
    "basic_auth_results = basic_auth_analysis(auth_df)\n",
    "basic_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Basic analysis completed in {basic_auth_time:.2f} seconds\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2.3 Machine Learning Analysis\n",
    "\n",
    "# %%\n",
    "def ml_auth_analysis(df):\n",
    "    \"\"\"ML-based authentication analysis using behavioral modeling\"\"\"\n",
    "    \n",
    "    print(\"ü§ñ ML AUTHENTICATION ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create time windows for behavioral analysis\n",
    "    print(\"\\nüîß Creating behavioral features with time windows...\")\n",
    "    \n",
    "    # Use 10-minute time windows\n",
    "    df['time_window'] = df['timestamp'].dt.floor('10min')\n",
    "    \n",
    "    # Create features per IP per time window\n",
    "    window_features = df.groupby(['source_ip', 'time_window']).agg({\n",
    "        'username': ['nunique', 'count'],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()],\n",
    "        'service': 'nunique'\n",
    "    })\n",
    "    \n",
    "    window_features.columns = ['unique_users', 'total_attempts', 'failures', 'successes', 'unique_services']\n",
    "    \n",
    "    # Calculate rates and ratios\n",
    "    window_features['failure_rate'] = window_features['failures'] / window_features['total_attempts']\n",
    "    window_features['attempts_per_minute'] = window_features['total_attempts'] / 10  # 10-minute windows\n",
    "    window_features['user_diversity'] = window_features['unique_users'] / window_features['total_attempts']\n",
    "    \n",
    "    # Fill NaN values\n",
    "    window_features = window_features.fillna(0)\n",
    "    \n",
    "    # Add IP-level behavioral features\n",
    "    ip_features = df.groupby('source_ip').agg({\n",
    "        'username': 'nunique',\n",
    "        'timestamp': ['count', lambda x: (x.max() - x.min()).total_seconds() / 3600],\n",
    "        'event_type': [lambda x: (x == 'login_failure').sum(), \n",
    "                      lambda x: (x == 'login_success').sum()]\n",
    "    })\n",
    "    \n",
    "    ip_features.columns = ['total_unique_users', 'total_attempts', 'session_duration_hours', \n",
    "                          'total_failures', 'total_successes']\n",
    "    ip_features['overall_failure_rate'] = ip_features['total_failures'] / ip_features['total_attempts']\n",
    "    \n",
    "    # Check if IP is external (simple heuristic)\n",
    "    ip_features['is_external'] = ~ip_features.index.str.startswith('192.168.')\n",
    "    ip_features['is_external'] = ip_features['is_external'].astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Created features for {len(window_features)} time windows across {len(ip_features)} IPs\")\n",
    "    \n",
    "    # Apply clustering to find unusual patterns in time windows\n",
    "    print(\"\\nüîç Applying DBSCAN clustering on time window features...\")\n",
    "    \n",
    "    # Select features for clustering\n",
    "    cluster_features = window_features[['unique_users', 'total_attempts', 'failure_rate', \n",
    "                                      'attempts_per_minute', 'user_diversity']].copy()\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(cluster_features)\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=3)\n",
    "    clusters = dbscan.fit_predict(features_scaled)\n",
    "    \n",
    "    # Add cluster labels\n",
    "    window_features['cluster'] = clusters\n",
    "    \n",
    "    # Analyze outliers (cluster -1)\n",
    "    outliers = window_features[window_features['cluster'] == -1]\n",
    "    \n",
    "    print(f\"\\nüö® ANOMALOUS TIME WINDOWS DETECTED: {len(outliers)}\")\n",
    "    \n",
    "    # Group outliers by IP for analysis\n",
    "    outlier_ips = outliers.groupby(level='source_ip').agg({\n",
    "        'total_attempts': ['sum', 'max'],\n",
    "        'failures': ['sum', 'max'],\n",
    "        'failure_rate': 'mean',\n",
    "        'attempts_per_minute': 'max',\n",
    "        'unique_users': 'max'\n",
    "    })\n",
    "    \n",
    "    outlier_ips.columns = ['total_attempts', 'max_attempts_per_window', 'total_failures', \n",
    "                          'max_failures_per_window', 'avg_failure_rate', \n",
    "                          'max_attempts_per_minute', 'max_users_per_window']\n",
    "    \n",
    "    # Sort by severity\n",
    "    outlier_ips['severity_score'] = (\n",
    "        outlier_ips['max_attempts_per_minute'] * 0.4 +\n",
    "        outlier_ips['avg_failure_rate'] * 0.3 +\n",
    "        outlier_ips['max_users_per_window'] * 0.3\n",
    "    )\n",
    "    \n",
    "    outlier_ips = outlier_ips.sort_values('severity_score', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ TOP SUSPICIOUS IPs BY ML ANALYSIS:\")\n",
    "    \n",
    "    for i, (ip, row) in enumerate(outlier_ips.head().iterrows()):\n",
    "        print(f\"\\n{i+1}. {ip} (severity score: {row['severity_score']:.2f})\")\n",
    "        print(f\"   üí• Total attempts: {row['total_attempts']}\")\n",
    "        print(f\"   üìà Max attempts/minute: {row['max_attempts_per_minute']:.1f}\")\n",
    "        print(f\"   ‚ùå Average failure rate: {row['avg_failure_rate']:.2%}\")\n",
    "        print(f\"   üë• Max users targeted in one window: {row['max_users_per_window']}\")\n",
    "        \n",
    "        # Show timeline for this IP\n",
    "        ip_data = df[df['source_ip'] == ip]\n",
    "        print(f\"   üìÖ Active period: {ip_data['timestamp'].min()} to {ip_data['timestamp'].max()}\")\n",
    "        \n",
    "        # Show most common usernames\n",
    "        top_users = ip_data['username'].value_counts().head(3)\n",
    "        print(f\"   üéØ Top targets: {dict(top_users)}\")\n",
    "    \n",
    "    return {\n",
    "        'window_features': window_features,\n",
    "        'ip_features': ip_features,\n",
    "        'outliers': outliers,\n",
    "        'outlier_ips': outlier_ips,\n",
    "        'clusters': clusters\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ ML AUTHENTICATION ANALYSIS\n",
      "==================================================\n",
      "\n",
      "üîß Creating behavioral features with time windows...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created features for 2876 time windows across 164 IPs\n",
      "\n",
      "üîç Applying DBSCAN clustering on time window features...\n",
      "\n",
      "üö® ANOMALOUS TIME WINDOWS DETECTED: 20\n",
      "\n",
      "üéØ TOP SUSPICIOUS IPs BY ML ANALYSIS:\n",
      "\n",
      "1. 203.0.113.15 (severity score: 9.60)\n",
      "   üí• Total attempts: 98.0\n",
      "   üìà Max attempts/minute: 6.0\n",
      "   ‚ùå Average failure rate: 100.00%\n",
      "   üë• Max users targeted in one window: 23.0\n",
      "   üìÖ Active period: 2025-08-07 09:35:24 to 2025-08-07 09:51:34\n",
      "   üéØ Top targets: {'admin': np.int64(11), 'root': np.int64(11), 'user': np.int64(9)}\n",
      "\n",
      "2. 192.0.2.123 (severity score: 9.28)\n",
      "   üí• Total attempts: 61.0\n",
      "   üìà Max attempts/minute: 5.2\n",
      "   ‚ùå Average failure rate: 100.00%\n",
      "   üë• Max users targeted in one window: 23.0\n",
      "   üìÖ Active period: 2025-08-07 11:35:24 to 2025-08-07 11:44:44\n",
      "   üéØ Top targets: {'guest': np.int64(11), 'root': np.int64(9), 'test': np.int64(5)}\n",
      "\n",
      "3. 198.51.100.42 (severity score: 8.30)\n",
      "   üí• Total attempts: 66.0\n",
      "   üìà Max attempts/minute: 5.0\n",
      "   ‚ùå Average failure rate: 100.00%\n",
      "   üë• Max users targeted in one window: 20.0\n",
      "   üìÖ Active period: 2025-08-07 09:35:24 to 2025-08-07 09:45:54\n",
      "   üéØ Top targets: {'guest': np.int64(9), 'root': np.int64(8), 'administrator': np.int64(8)}\n",
      "\n",
      "4. 185.199.108.153 (severity score: 7.62)\n",
      "   üí• Total attempts: 58.0\n",
      "   üìà Max attempts/minute: 4.8\n",
      "   ‚ùå Average failure rate: 100.00%\n",
      "   üë• Max users targeted in one window: 18.0\n",
      "   üìÖ Active period: 2025-08-07 11:35:24 to 2025-08-07 11:44:14\n",
      "   üéØ Top targets: {'admin': np.int64(10), 'administrator': np.int64(8), 'user': np.int64(7)}\n",
      "\n",
      "5. 192.168.3.20 (severity score: 1.76)\n",
      "   üí• Total attempts: 5.0\n",
      "   üìà Max attempts/minute: 0.5\n",
      "   ‚ùå Average failure rate: 20.00%\n",
      "   üë• Max users targeted in one window: 5.0\n",
      "   üìÖ Active period: 2025-08-07 05:50:11 to 2025-08-07 12:41:11\n",
      "   üéØ Top targets: {'user143': np.int64(2), 'user078': np.int64(2), 'user050': np.int64(1)}\n",
      "\n",
      "‚è±Ô∏è ML analysis completed in 0.97 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time the ML analysis\n",
    "start_time = time.time()\n",
    "ml_auth_results = ml_auth_analysis(auth_df)\n",
    "ml_auth_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è ML analysis completed in {ml_auth_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to generate the datasets used in these modules may be found below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_traffic_data(num_records=10000):\n",
    "    \"\"\"Generate realistic network traffic data with hidden anomalies\"\"\"\n",
    "    \n",
    "    # Normal traffic patterns\n",
    "    normal_sources = [f\"192.168.1.{i}\" for i in range(10, 100)]\n",
    "    normal_destinations = [f\"10.0.{i}.{j}\" for i in range(1, 5) for j in range(10, 50)]\n",
    "    common_ports = [80, 443, 22, 25, 53, 110, 143, 993, 995]\n",
    "    \n",
    "    # Generate timestamps over last 24 hours\n",
    "    start_time = dt.now() - timedelta(hours=24)\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Normal traffic (90% of data)\n",
    "    for _ in range(int(num_records * 0.90)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        source = random.choice(normal_sources)\n",
    "        destination = random.choice(normal_destinations)\n",
    "        port = random.choice(common_ports)\n",
    "        bytes_sent = random.randint(64, 1500)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    # Suspicious traffic (10% of data) - More obvious for Excel detection\n",
    "    suspicious_ips = ['185.220.70.43', '194.233.164.24', '91.234.99.12']\n",
    "    suspicious_ports = [1337, 4444, 8080, 9999, 31337]\n",
    "    \n",
    "    for _ in range(int(num_records * 0.10)):\n",
    "        timestamp = start_time + timedelta(seconds=random.randint(0, 86400))\n",
    "        \n",
    "        if random.random() < 0.4:  # External suspicious IP\n",
    "            source = random.choice(suspicious_ips)\n",
    "            destination = random.choice(normal_destinations)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(5000, 50000)  # Much larger transfers\n",
    "        else:  # Internal lateral movement\n",
    "            source = random.choice(normal_sources)\n",
    "            destination = random.choice(normal_sources)\n",
    "            port = random.choice(suspicious_ports)\n",
    "            bytes_sent = random.randint(2000, 10000)\n",
    "        \n",
    "        data.append({\n",
    "            'timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_ip': source,\n",
    "            'destination_ip': destination,\n",
    "            'destination_port': port,\n",
    "            'bytes': bytes_sent,\n",
    "            'protocol': 'TCP'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.sample(frac=1).reset_index(drop=True)  # Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "traffic_df = generate_network_traffic_data(500000)\n",
    "print(f\"üìä Generated {len(traffic_df):,} network traffic records\")\n",
    "print(f\"üìÖ Time range: {traffic_df['timestamp'].min()} to {traffic_df['timestamp'].max()}\")\n",
    "\n",
    "# Save to CSV for Excel analysis\n",
    "traffic_df.to_csv(f\"{DATA_DIR}/network_traffic.csv\", index=False)\n",
    "print(\"üíæ Saved to network_traffic.csv\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüîç Sample of the data:\")\n",
    "display(traffic_df.head())"
   ]
>>>>>>> main
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
